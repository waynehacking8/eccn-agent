#!/usr/bin/env python3
"""
ECCNåˆ†é¡å·¥å…·å¢å¼·ç³»çµ±
æ•´åˆå¤–éƒ¨APIå’ŒWebSearchåŠŸèƒ½ä»¥æé«˜åˆ†é¡æº–ç¢ºæ€§
"""

import json
import requests
import re
import time
from typing import Dict, List, Optional, Any
import logging
from datetime import datetime

class ECCNToolEnhancer:
    """ECCNåˆ†é¡å·¥å…·å¢å¼·å™¨"""
    
    def __init__(self, logger: logging.Logger = None):
        self.logger = logger or logging.getLogger(__name__)
        
        # APIé…ç½® - å¾ç’°å¢ƒè®Šé‡è®€å–
        import os
        self.mouser_api_key = os.environ.get('MOUSER_API_KEY', "773b916e-0f6c-4a86-a896-b3b435be5389")  # Mouser APIå¯†é‘°
        self.digikey_api_key = None  # éœ€è¦è¨»å†Šç²å–
        
        # å·¥å…·é…ç½®
        self.tools_config = {
            'websearch': {'enabled': True, 'timeout': 30},
            'mouser_api': {'enabled': True, 'timeout': 15},
            'digikey_api': {'enabled': False, 'timeout': 15},  # å¯é¸
            'cross_reference': {'enabled': True, 'timeout': 45}
        }
        
        # ECCNæ¨¡å¼å’Œé—œéµå­—åº«
        self.eccn_patterns = {
            'EAR99': {
                'keywords': ['commercial', 'consumer', 'office', 'unmanaged', 'basic'],
                'temp_range': [(0, 70), (-20, 70)],
                'features': ['simple', 'standard', 'basic']
            },
            '5A991': {
                'keywords': ['industrial', 'ethernet', 'switch', 'managed'],
                'temp_range': [(-40, 85), (-20, 80)],
                'features': ['managed', 'industrial', 'rugged']
            },
            '5A991.b': {
                'keywords': ['security', 'encryption', 'vlan', 'advanced'],
                'temp_range': [(-40, 85)],
                'features': ['security', 'encryption', 'advanced_management']
            },
            '5A991.b.1': {
                'keywords': ['high-speed', 'gigabit', 'fiber', 'performance'],
                'temp_range': [(-40, 85)],
                'features': ['high_speed', 'gigabit', 'fiber_optic']
            },
            '4A994': {
                'keywords': ['management', 'monitoring', 'control', 'poe'],
                'temp_range': [(-40, 85)],
                'features': ['power_management', 'monitoring', 'control_functions']
            }
        }

    def search_mouser_eccn(self, product_model: str) -> Optional[Dict]:
        """
        ä½¿ç”¨Mouser APIæŸ¥è©¢ç”¢å“çš„å®˜æ–¹ECCNåˆ†é¡
        """
        try:
            self.logger.info(f" Mouser APIæŸ¥è©¢: {product_model}")
            
            # Mouser APIæœå°‹ç«¯é» (ä¿®æ­£ç‚ºv1.0æ ¼å¼)
            url = f"https://api.mouser.com/api/v1.0/search/keyword?apiKey={self.mouser_api_key}"
            
            headers = {
                'accept': 'application/json',
                'Content-Type': 'application/json'
            }
            
            # å˜—è©¦å¤šç¨®æœå°‹ç­–ç•¥
            search_strategies = [
                product_model,  # åŸºæœ¬æœå°‹
                f"Advantech {product_model}",  # åŒ…å«è£½é€ å•†
                product_model.replace('-', ''),  # ç§»é™¤é€£å­—ç¬¦
                f"{product_model}-02A1E",  # å¸¸è¦‹è®Šé«”
                f"577-{product_model}",  # Mouser ç·¨è™Ÿæ ¼å¼
                product_model.split('-')[0] if '-' in product_model else product_model,  # åŸºæœ¬å‹è™Ÿ
            ]
            
            for search_keyword in search_strategies:
                self.logger.info(f"ğŸ” å˜—è©¦æœå°‹: {search_keyword}")
                
                payload = {
                    "SearchByKeywordRequest": {
                        "keyword": search_keyword,
                        "records": 10,  # å¢åŠ æœå°‹çµæœ
                        "startingRecord": 0,
                        "searchOptions": "ExcludeNonBuyable",
                        "searchWithYourSignUpLanguage": "false"
                    }
                }
                
                response = requests.post(
                    url, 
                    headers=headers, 
                    json=payload,
                    timeout=self.tools_config['mouser_api']['timeout']
                )
                
                if response.status_code != 200:
                    self.logger.warning(f"âš ï¸ Mouser APIè«‹æ±‚å¤±æ•—: {response.status_code} - {search_keyword}")
                    continue
                    
                try:
                    data = response.json()
                    parts = data.get('SearchResults', {}).get('Parts', [])
                    self.logger.info(f"ğŸ“Š Mouser APIéŸ¿æ‡‰: {search_keyword} - {len(parts)} å€‹çµæœ")
                except Exception as json_error:
                    self.logger.error(f"âŒ Mouser API JSONè§£æå¤±æ•—: {search_keyword} - {str(json_error)}")
                    continue
                
                self.logger.info(f"ğŸ“Š æœå°‹ '{search_keyword}' æ‰¾åˆ° {len(parts)} å€‹ç”¢å“")
                
                # æª¢æŸ¥æ¯å€‹æ‰¾åˆ°çš„ç”¢å“
                for part in parts:
                    part_number = part.get('MouserPartNumber', '')
                    manufacturer = part.get('Manufacturer', '')
                    description = part.get('Description', '')
                    
                    # èª¿è©¦ï¼šé¡¯ç¤ºç”¢å“çš„æ‰€æœ‰ECCNç›¸é—œæ¬„ä½
                    compliance = part.get('ProductCompliance', [])
                    legacy_eccn = part.get('ExportControlClassificationNumber', '')
                    
                    self.logger.info(f"ğŸ” æª¢æŸ¥ç”¢å“: {part_number} ({manufacturer})")
                    self.logger.info(f"ğŸ“‹ ProductCompliance: {compliance}")
                    self.logger.info(f"ğŸ“‹ Legacy ECCN: '{legacy_eccn}'")
                    
                    # ä½¿ç”¨æ”¹é€²çš„åŒ¹é…é‚è¼¯
                    if self._is_related_product(part_number, description, product_model, manufacturer):
                        self.logger.info(f"ğŸ” åˆæ­¥åŒ¹é…ç”¢å“: {part_number}")
                        
                        # **æ–°å¢è¦æ ¼æ ¡å°æ­¥é©Ÿ**
                        if not self._verify_product_specifications(part, product_model, description):
                            self.logger.info(f"âš ï¸ è¦æ ¼æ ¡å°ä¸ç¬¦ï¼Œè·³é: {part_number}")
                            continue
                            
                        self.logger.info(f"âœ… è¦æ ¼æ ¡å°é€šé: {part_number}")
                        
                        # 1. æª¢æŸ¥ProductComplianceä¸­çš„ECCN (å„ªå…ˆ)
                        compliance = part.get('ProductCompliance', [])
                        for comp in compliance:
                            if comp.get('ComplianceName') == 'ECCN':
                                eccn = comp.get('ComplianceValue', '').strip()
                                # æ›´åš´æ ¼çš„ECCNé©—è­‰ - å¿…é ˆæ˜¯æœ‰æ•ˆçš„ECCNæ ¼å¼
                                if eccn and eccn not in ['N/A', 'Not Available', '', 'TBD', 'null', 'NULL', '-', 'â€”'] and self._is_valid_eccn_format(eccn):
                                    eccn = self._normalize_eccn_format(eccn)
                                    self.logger.info(f"âœ… Mouseræ‰¾åˆ°æœ‰æ•ˆECCN: {eccn} (æœå°‹è©: {search_keyword})")
                                    return {
                                        'source': 'mouser_api_direct',
                                        'eccn_code': eccn,
                                        'part_number': part_number,
                                        'manufacturer': manufacturer,
                                        'description': description,
                                        'confidence': 'high',
                                        'method': 'product_compliance',
                                        'search_keyword': search_keyword,
                                        'reasoning': f'Mouser APIç›´æ¥æŸ¥è©¢ "{search_keyword}" æ‰¾åˆ°ç”¢å“ {part_number}: {eccn}'
                                    }
                                else:
                                    self.logger.info(f"âŒ Mouser ECCNç„¡æ•ˆæˆ–ç‚ºç©º: '{eccn}' (ç”¢å“: {part_number})")
                        
                        # 2. å‚™ç”¨ï¼šæª¢æŸ¥èˆŠæ ¼å¼çš„ECCNæ¬„ä½
                        eccn = part.get('ExportControlClassificationNumber', '').strip()
                        if eccn and eccn not in ['N/A', 'Not Available', '', 'TBD', 'null', 'NULL', '-', 'â€”'] and self._is_valid_eccn_format(eccn):
                            eccn = self._normalize_eccn_format(eccn)
                            self.logger.info(f"âœ… Mouseræ‰¾åˆ°æœ‰æ•ˆECCN (Legacy): {eccn} (æœå°‹è©: {search_keyword})")
                            return {
                                'source': 'mouser_api_direct',
                                'eccn_code': eccn,
                                'part_number': part_number,
                                'manufacturer': manufacturer,
                                'description': description,
                                'confidence': 'high',
                                'method': 'legacy_field',
                                'search_keyword': search_keyword,
                                'reasoning': f'Mouser APIç›´æ¥æŸ¥è©¢ "{search_keyword}" æ‰¾åˆ°ç”¢å“ {part_number}: {eccn}'
                            }
                        else:
                            self.logger.info(f"âŒ Mouser Legacy ECCNç„¡æ•ˆæˆ–ç‚ºç©º: '{eccn}' (ç”¢å“: {part_number})")
            
            # æ‰€æœ‰æœå°‹ç­–ç•¥éƒ½æ²’æ‰¾åˆ°
            self.logger.warning(f"âš ï¸ Mouseræ‰€æœ‰æœå°‹ç­–ç•¥éƒ½æœªæ‰¾åˆ°ECCN: {search_strategies}")
            return None
                
        except Exception as e:
            self.logger.error(f" Mouser APIä¾‹å¤–: {str(e)}")
            return None

    def search_web_eccn_references(self, product_model: str, product_description: str = "") -> List[Dict]:
        """
        ä½¿ç”¨WebSearchæŸ¥è©¢ECCNç›¸é—œè³‡è¨Š
        """
        try:
            self.logger.info(f" WebSearchæŸ¥è©¢: {product_model}")
            
            # æ§‹å»ºæœç´¢æŸ¥è©¢
            search_queries = [
                f"{product_model} ECCN export control classification",
                f"{product_model} export control number",
                f'"{product_model}" ECCN',
                f"{product_model} commerce control list"
            ]
            
            results = []
            
            for query in search_queries:
                try:
                    # æ¨¡æ“¬WebSearchè«‹æ±‚ (éœ€è¦å¯¦éš›APIå¯¦ç¾)
                    search_result = self._perform_web_search(query)
                    if search_result:
                        results.extend(search_result)
                        
                    time.sleep(1)  # é¿å…éåº¦è«‹æ±‚
                except Exception as e:
                    self.logger.warning(f"æœç´¢æŸ¥è©¢å¤±æ•—: {query} - {str(e)}")
                    continue
            
            # åˆ†ææœç´¢çµæœä¸­çš„ECCNæ¨¡å¼
            eccn_matches = self._extract_eccn_from_search_results(results)
            
            self.logger.info(f" WebSearchæ‰¾åˆ°{len(eccn_matches)}å€‹ECCNåƒè€ƒ")
            return eccn_matches
            
        except Exception as e:
            self.logger.error(f" WebSearchä¾‹å¤–: {str(e)}")
            return []

    def _perform_web_search(self, query: str) -> List[Dict]:
        """
        åŸ·è¡Œå¯¦éš›çš„ç¶²è·¯æœç´¢ (éœ€è¦æœç´¢API)
        é€™è£¡ä½¿ç”¨æ¨¡æ“¬å¯¦ç¾ï¼Œå¯¦éš›éœ€è¦æ•´åˆçœŸå¯¦æœç´¢API
        """
        # æ¨¡æ“¬æœç´¢çµæœ
        mock_results = [
            {
                'title': f'ECCN Classification for {query.split()[0]}',
                'url': 'https://example.com/eccn-database',
                'snippet': 'This product is classified under ECCN 5A991 according to US export control regulations...',
                'source': 'regulatory_database'
            }
        ]
        return mock_results

    def _extract_eccn_from_search_results(self, search_results: List[Dict]) -> List[Dict]:
        """å¾æœç´¢çµæœä¸­æå–ECCNä»£ç¢¼"""
        eccn_pattern = re.compile(r'\b(EAR99|[0-9][A-Z][0-9]{3}(?:\.[a-z](?:\.[0-9]+)?)?)\b')
        
        matches = []
        for result in search_results:
            text = f"{result.get('title', '')} {result.get('snippet', '')}"
            found_eccns = eccn_pattern.findall(text)
            
            for eccn in found_eccns:
                matches.append({
                    'source': 'websearch',
                    'eccn_code': eccn,
                    'url': result.get('url'),
                    'context': result.get('snippet', ''),
                    'confidence': self._assess_search_confidence(result, eccn)
                })
        
        return matches

    def _assess_search_confidence(self, result: Dict, eccn: str) -> str:
        """è©•ä¼°æœç´¢çµæœçš„å¯ä¿¡åº¦"""
        confidence_indicators = {
            'high': ['bis.doc.gov', 'export.gov', 'official', 'government'],
            'medium': ['manufacturer', 'datasheet', 'specification'],
            'low': ['forum', 'discussion', 'estimate', 'approximate']
        }
        
        url = result.get('url', '').lower()
        text = f"{result.get('title', '')} {result.get('snippet', '')}".lower()
        
        for level, indicators in confidence_indicators.items():
            if any(indicator in url or indicator in text for indicator in indicators):
                return level
        
        return 'low'

    def cross_reference_eccn(self, product_model: str, pdf_content: str = "") -> Dict:
        """
        äº¤å‰åƒè€ƒå¤šå€‹ä¾†æºçš„ECCNè³‡è¨Š
        """
        self.logger.info(f" é–‹å§‹äº¤å‰åƒè€ƒ: {product_model}")
        
        sources = {}
        
        # 1. Mouser APIæŸ¥è©¢
        if self.tools_config['mouser_api']['enabled']:
            mouser_result = self.search_mouser_eccn(product_model)
            if mouser_result:
                sources['mouser'] = mouser_result
        
        # 2. å¢å¼·å‹WebSearchæŸ¥è©¢
        if self.tools_config['websearch']['enabled']:
            try:
                from websearch import ECCNWebSearcher
                web_searcher = ECCNWebSearcher(self.logger)
                web_results = web_searcher.search_eccn_information(product_model, "Advantech")
                
                if web_results:
                    sources['websearch'] = web_results[:5]  # é™åˆ¶æ•¸é‡
                    self.logger.info(f"âœ… WebSearchæ‰¾åˆ° {len(web_results)} å€‹çµæœ")
                else:
                    # å‚™ç”¨ï¼šä½¿ç”¨åŸå§‹æœç´¢
                    web_results = self.search_web_eccn_references(product_model, pdf_content)
                    if web_results:
                        sources['websearch'] = web_results
            except Exception as e:
                self.logger.warning(f"âš ï¸ å¢å¼·å‹WebSearchå¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨æœç´¢: {str(e)}")
                # å‚™ç”¨ï¼šä½¿ç”¨åŸå§‹æœç´¢
                web_results = self.search_web_eccn_references(product_model, pdf_content)
                if web_results:
                    sources['websearch'] = web_results
        
        # 3. æŠ€è¡“åˆ†æ (åŸºæ–¼PDFå…§å®¹)
        if pdf_content:
            tech_analysis = self._analyze_technical_features(pdf_content)
            sources['technical_analysis'] = tech_analysis
        
        # 4. ç¶œåˆåˆ†æ
        final_recommendation = self._synthesize_eccn_sources(sources, product_model)
        
        self.logger.info(f" äº¤å‰åƒè€ƒå®Œæˆ: {final_recommendation.get('eccn_code', 'Unknown')}")
        return final_recommendation

    def _analyze_technical_features(self, pdf_content: str) -> Dict:
        """åŸºæ–¼PDFæŠ€è¡“å…§å®¹åˆ†æECCN"""
        features_found = {}
        
        # åˆ†ææŠ€è¡“ç‰¹å¾µ
        for eccn, patterns in self.eccn_patterns.items():
            score = 0
            found_features = []
            
            # é—œéµå­—åŒ¹é…
            for keyword in patterns['keywords']:
                if keyword.lower() in pdf_content.lower():
                    score += 1
                    found_features.append(keyword)
            
            # æº«åº¦ç¯„åœåˆ†æ
            temp_matches = re.findall(r'(-?\d+)\s*[Â°â„ƒC]\s*(?:to|~|-)\s*([+-]?\d+)\s*[Â°â„ƒC]', pdf_content)
            for temp_range in patterns.get('temp_range', []):
                for match in temp_matches:
                    temp_min, temp_max = int(match[0]), int(match[1])
                    if temp_min >= temp_range[0] and temp_max <= temp_range[1]:
                        score += 2
                        found_features.append(f"temp_range_{temp_min}_{temp_max}")
            
            if score > 0:
                features_found[eccn] = {
                    'score': score,
                    'features': found_features,
                    'confidence': 'high' if score >= 3 else 'medium' if score >= 2 else 'low'
                }
        
        # é¸æ“‡æœ€é«˜åˆ†çš„ECCN
        if features_found:
            best_eccn = max(features_found.keys(), key=lambda x: features_found[x]['score'])
            return {
                'source': 'technical_analysis',
                'eccn_code': best_eccn,
                'confidence': features_found[best_eccn]['confidence'],
                'features_found': features_found[best_eccn]['features'],
                'analysis_details': features_found
            }
        
        return {
            'source': 'technical_analysis',
            'eccn_code': 'EAR99',  # é è¨­ç‚ºå•†ç”¨
            'confidence': 'low',
            'features_found': [],
            'reason': 'insufficient_technical_features'
        }

    def _synthesize_eccn_sources(self, sources: Dict, product_model: str) -> Dict:
        """ç¶œåˆå¤šå€‹ä¾†æºçš„ECCNè³‡è¨Š"""
        recommendations = []
        
        # æ”¶é›†æ‰€æœ‰ä¾†æºçš„å»ºè­°
        for source_name, source_data in sources.items():
            if source_name == 'websearch' and isinstance(source_data, list):
                for item in source_data:
                    recommendations.append(item)
            elif isinstance(source_data, dict) and 'eccn_code' in source_data:
                recommendations.append(source_data)
        
        if not recommendations:
            return {
                'eccn_code': 'EAR99',
                'confidence': 'low',
                'method': 'default_fallback',
                'reasoning': 'ç„¡å¤–éƒ¨è³‡æ–™æºç¢ºèªï¼Œé è¨­ç‚ºå•†ç”¨åˆ†é¡',
                'sources_consulted': list(sources.keys())
            }
        
        # ä¿¡å¿ƒåº¦æ¬Šé‡
        confidence_weights = {'high': 3, 'medium': 2, 'low': 1}
        
        # ä¾†æºæ¬Šé‡
        source_weights = {
            'mouser': 5,
            'digikey': 5,
            'technical_analysis': 3,
            'websearch': 2
        }
        
        # è¨ˆç®—åŠ æ¬Šåˆ†æ•¸
        eccn_scores = {}
        for rec in recommendations:
            eccn = rec.get('eccn_code', 'EAR99')
            confidence = rec.get('confidence', 'low')
            source = rec.get('source', 'unknown')
            
            score = confidence_weights.get(confidence, 1) * source_weights.get(source, 1)
            
            if eccn not in eccn_scores:
                eccn_scores[eccn] = {'score': 0, 'sources': [], 'details': []}
            
            eccn_scores[eccn]['score'] += score
            eccn_scores[eccn]['sources'].append(source)
            eccn_scores[eccn]['details'].append(rec)
        
        # é¸æ“‡æœ€é«˜åˆ†çš„ECCN
        if eccn_scores:
            best_eccn = max(eccn_scores.keys(), key=lambda x: eccn_scores[x]['score'])
            best_data = eccn_scores[best_eccn]
            
            # è¨ˆç®—ç¶œåˆä¿¡å¿ƒåº¦
            total_score = best_data['score']
            max_possible = len(recommendations) * 3 * 5  # æœ€é«˜å¯èƒ½åˆ†æ•¸
            confidence_ratio = total_score / max_possible if max_possible > 0 else 0
            
            if confidence_ratio >= 0.7:
                final_confidence = 'high'
            elif confidence_ratio >= 0.4:
                final_confidence = 'medium'
            else:
                final_confidence = 'low'
            
            return {
                'eccn_code': best_eccn,
                'confidence': final_confidence,
                'method': 'cross_reference_synthesis',
                'reasoning': f'åŸºæ–¼{len(best_data["sources"])}å€‹ä¾†æºçš„äº¤å‰é©—è­‰: {", ".join(set(best_data["sources"]))}',
                'score_details': eccn_scores,
                'sources_consulted': list(sources.keys()),
                'total_sources': len(recommendations)
            }
        
        # å›é€€åˆ°é è¨­
        return {
            'eccn_code': 'EAR99',
            'confidence': 'low',
            'method': 'synthesis_fallback',
            'reasoning': 'ç¶œåˆåˆ†æå¾Œç„¡æ³•ç¢ºå®šï¼Œé è¨­ç‚ºå•†ç”¨åˆ†é¡',
            'sources_consulted': list(sources.keys())
        }

    def _is_model_match(self, api_model: str, target_model: str) -> bool:
        """æª¢æŸ¥APIè¿”å›çš„å‹è™Ÿæ˜¯å¦åŒ¹é…ç›®æ¨™å‹è™Ÿ"""
        # ç§»é™¤å¸¸è¦‹çš„åˆ†éš”ç¬¦å’Œè®Šé«”
        api_clean = re.sub(r'[-_\s]', '', api_model.upper())
        target_clean = re.sub(r'[-_\s]', '', target_model.upper())
        
        return api_clean == target_clean or target_clean in api_clean

    def _is_related_product(self, part_number: str, description: str, target_model: str, manufacturer: str, strict_match: bool = True) -> bool:
        """æ”¹é€²çš„ç”¢å“åŒ¹é…é‚è¼¯ï¼Œæª¢æŸ¥ç”¢å“æ˜¯å¦ç›¸é—œ
        
        Args:
            strict_match: True for exact matches (direct API), False for fuzzy matches (similarity search)
        """
        if not part_number:
            return False
        
        # è£½é€ å•†å¿…é ˆæ˜¯Advantechï¼ˆé‡å°WISEç³»åˆ—ï¼‰
        if target_model.startswith('WISE') and manufacturer.lower() != 'advantech':
            return False
        
        target_clean = target_model.upper().replace('-', '').replace('_', '')
        part_clean = part_number.upper().replace('-', '').replace('_', '')
        
        if strict_match:
            # å¯¬é¬†åç¨±åŒ¹é… + åš´æ ¼è¦æ ¼æ ¡å°ç­–ç•¥
            # å…è¨±æ›´å¤šå€™é¸ç”¢å“é€²å…¥ï¼Œç”±è¦æ ¼æ ¡å°ä¾†ç²¾ç¢ºè­˜åˆ¥
            if target_clean == part_clean:
                return True
            # å…è¨±ç›®æ¨™å‹è™ŸåŒ…å«åœ¨éƒ¨ä»¶è™Ÿä¸­ (æ¢å¾©åŸä¾†çš„å¯¬é¬†åŒ¹é…)
            if target_clean in part_clean:
                return True
            return False
        else:
            # æ¨¡ç³ŠåŒ¹é…ï¼šç”¨æ–¼ç›¸ä¼¼ç”¢å“æœç´¢
            if target_clean in part_clean:
                return True
            
            # æè¿°åŒ¹é…ï¼šç”¢å“æè¿°ä¸­åŒ…å«ç›®æ¨™å‹è™Ÿ
            if description and target_model.upper() in description.upper():
                return True
        
        return False
    
    def _verify_product_specifications(self, mouser_part: dict, target_model: str, pdf_content: str = "") -> bool:
        """
        è¦æ ¼æ ¡å°ï¼šç¢ºèªMouserç”¢å“èˆ‡PDFç”¢å“è¦æ ¼ä¸€è‡´ (å¯¬é¬†ç‰ˆæœ¬)
        åªæ ¡å°é—œéµçš„ä¸åŒ¹é…æƒ…æ³
        """
        try:
            part_number = mouser_part.get('MouserPartNumber', '')
            description = mouser_part.get('Description', '').lower()
            manufacturer = mouser_part.get('Manufacturer', '').lower()
            
            # åŸºæœ¬æª¢æŸ¥ï¼šè£½é€ å•†å¿…é ˆæ˜¯Advantech
            if 'advantech' not in manufacturer:
                self.logger.info(f"âŒ è£½é€ å•†ä¸åŒ¹é…: {manufacturer}")
                return False
            
            # **ç²¾ç¢ºç”¢å“åŒ¹é…** - é¿å…EKI-5728åŒ¹é…åˆ°EKI-5728I-AE
            target_clean = target_model.upper().replace('-', '').replace('_', '')
            part_clean = part_number.upper().replace('-', '').replace('_', '')
            
            # ç§»é™¤Mouserç”¢å“è™Ÿå‰ç¶´ (å¦‚ 923-)
            import re
            part_core = re.sub(r'^\d+', '', part_clean)
            
            # ç²¾ç¢ºåŒ¹é…ï¼šå¿…é ˆå®Œå…¨ç›¸åŒ
            if target_clean == part_core:
                self.logger.info(f"âœ… ç²¾ç¢ºç”¢å“åŒ¹é…: {target_model} = {part_number}")
                return True
            elif part_core.startswith(target_clean) and len(part_core) > len(target_clean):
                # **åŠŸèƒ½æ€§å·®ç•°æª¢æ¸¬** - æª¢æ¸¬Iã€MIã€LIç­‰åŠŸèƒ½ä»£ç¢¼å·®ç•°
                suffix = part_core[len(target_clean):]
                self.logger.info(f"ğŸ” ç™¼ç¾å¯èƒ½è®Šé«”: {target_model} â†’ {part_number} (å¾Œç¶´: {suffix})")
                
                # æª¢æ¸¬åŠŸèƒ½æ€§å¾Œç¶´ (I=Industrial, MI=Managed Industrial, LI=Layer2 Industrialç­‰)
                functional_suffixes = ['I', 'MI', 'LI', 'SI', 'FI', 'GI', 'CI', 'PI', 'S', 'M', 'G', 'F', 'C', 'P']
                geographic_suffixes = ['AU', 'US', 'EU', 'AS', 'CN', 'JP', 'KR', 'TW', 'HK', 'UK', 'DE', 'FR', 'U', 'E', 'J', 'K', 'H']
                
                # é¦–å…ˆæª¢æŸ¥åœ°ç†å€åŸŸå·®ç•° (AU, USç­‰)
                for geo_suffix in geographic_suffixes:
                    if suffix == geo_suffix or suffix.startswith(geo_suffix + '-') or suffix.endswith('-' + geo_suffix):
                        self.logger.info(f"âŒ æª¢æ¸¬åˆ°åœ°ç†å€åŸŸå·®ç•°: {target_model} vs {part_number}")
                        self.logger.info(f"   - ç›®æ¨™ç”¢å“: {target_model}")
                        self.logger.info(f"   - Mouserç”¢å“: {part_number} (å€åŸŸ: {geo_suffix})")
                        self.logger.info(f"   - å¾Œç¶´åˆ†æ: '{suffix}' åŒ¹é…å€åŸŸä»£ç¢¼ '{geo_suffix}'")
                        return False
                
                # å†æª¢æŸ¥åŠŸèƒ½æ€§å·®ç•°
                for func_suffix in functional_suffixes:
                    if suffix.startswith(func_suffix):
                        self.logger.info(f"âŒ æª¢æ¸¬åˆ°åŠŸèƒ½æ€§å·®ç•°: {target_model} vs {part_number}")
                        self.logger.info(f"   - ç›®æ¨™ç”¢å“: {target_model} (åŸºæœ¬å‹)")
                        self.logger.info(f"   - Mouserç”¢å“: {part_number} (åŠŸèƒ½: {func_suffix})")
                        return False
                
                # éåŠŸèƒ½æ€§å¾Œç¶´ï¼Œå…è¨±é€šé
                self.logger.info(f"âœ… å…è¨±è®Šé«”é€²å…¥è¦æ ¼æ ¡å°: {part_number}")
                return True
            else:
                self.logger.info(f"âŒ ç”¢å“å‹è™Ÿä¸åŒ¹é…: {target_model} vs {part_number}")
            
            # ç³»åˆ—æª¢æŸ¥
            target_series = self._extract_product_series(target_model)
            part_series = self._extract_product_series(part_number)
            
            if target_series and part_series and target_series != part_series:
                if not (target_series in part_series or part_series in target_series):
                    self.logger.info(f"âŒ ç”¢å“ç³»åˆ—å·®ç•°éå¤§: {target_series} vs {part_series}")
                    return False
                
            self.logger.info(f"âœ… è¦æ ¼æ ¡å°é€šé: {part_number}")
            return True
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ è¦æ ¼æ ¡å°ç•°å¸¸ï¼Œå…è¨±é€šé: {str(e)}")
            return True  # ç•°å¸¸æ™‚å…è¨±é€šé
    
    def _extract_product_series(self, model: str) -> str:
        """æå–ç”¢å“ç³»åˆ—ä»£ç¢¼ - æ”¯æŒ Mouser æ ¼å¼"""
        if not model:
            return ""
        
        import re
        
        # ç§»é™¤ Mouser ç”¢å“è™Ÿå‰ç¶´ (å¦‚ 923-)
        clean_model = re.sub(r'^\d+-', '', model.upper())
        
        # æå–ä¸»è¦ç”¢å“ç³»åˆ—
        # EKI-2525LI-AE -> EKI-2525LI (ä¿ç•™åŠŸèƒ½ä»£ç¢¼)
        # EKI-2705G-1GPI-A -> EKI-2705G-1GPI (å»æ‰åœ°å€ä»£ç¢¼)
        
        # å…ˆåŒ¹é…è¤‡é›œæ ¼å¼ (åŒ…å«é€£å­—ç¬¦å’ŒåŠŸèƒ½ä»£ç¢¼)
        match = re.match(r'(EKI-\d{4}[A-Z]*(?:-\d*[A-Z]*)*)', clean_model)
        if match:
            base_series = match.group(1)
            # å»æ‰æœ€å¾Œçš„åœ°å€ä»£ç¢¼
            base_series = re.sub(r'-([A-Z]{1,3})$', '', base_series)
            return base_series
            
        # ç°¡å–®æ ¼å¼åŒ¹é…
        match = re.match(r'(EKI-\d{4}[A-Z]*)', clean_model)
        if match:
            return match.group(1)
            
        return clean_model[:15] if len(clean_model) >= 15 else clean_model
    
    def _region_codes_compatible(self, target_model: str, part_number: str) -> bool:
        """æª¢æŸ¥åœ°å€ä»£ç¢¼æ˜¯å¦å…¼å®¹ - é˜²æ­¢ A vs AU çš„éŒ¯èª¤åŒ¹é…"""
        import re
        
        # æå–åœ°å€ä»£ç¢¼
        target_region = self._extract_region_code(target_model)
        part_region = self._extract_region_code(part_number)
        
        # å®Œå…¨åŒ¹é…æ˜¯æœ€ç†æƒ³çš„
        if target_region == part_region:
            self.logger.info(f"âœ… åœ°å€ä»£ç¢¼å®Œå…¨åŒ¹é…: {target_region}")
            return True
        
        # æª¢æŸ¥æ˜¯å¦æ˜¯ä¸å…¼å®¹çš„åœ°å€ä»£ç¢¼ - æ›´æ™ºèƒ½çš„æª¢æŸ¥
        if target_region and part_region and target_region != part_region:
            # ç‰¹åˆ¥æª¢æŸ¥æ˜é¡¯è¡çªçš„æƒ…æ³
            conflicting_pairs = [
                ('A', 'AU'), ('AU', 'A'),  # A vs AU è¡çª
                ('AE', 'BE'), ('BE', 'AE'), # ä¸åŒåœ°å€ç‰ˆæœ¬
                ('US', 'EU'), ('EU', 'US')  # ä¸åŒå¸‚å ´ç‰ˆæœ¬
            ]
            
            for pair in conflicting_pairs:
                if (target_region, part_region) == pair:
                    self.logger.info(f"âŒ åœ°å€ä»£ç¢¼è¡çª: {target_region} vs {part_region}")
                    return False
            
            # å°æ–¼å…¶ä»–åœ°å€ä»£ç¢¼å·®ç•°ï¼Œçµ¦äºˆæ›´å¤šå¯¬å®¹
            # ä¾‹å¦‚ -AE vs -02A1E å¯èƒ½æ˜¯åŒä¸€ç”¢å“çš„ä¸åŒç‰ˆæœ¬
            if len(target_region) <= 2 and len(part_region) > 3:
                self.logger.info(f"â„¹ï¸ åœ°å€ä»£ç¢¼ç‰ˆæœ¬å·®ç•°: {target_region} vs {part_region} (å…è¨±)")
                return True
            elif len(part_region) <= 2 and len(target_region) > 3:
                self.logger.info(f"â„¹ï¸ åœ°å€ä»£ç¢¼ç‰ˆæœ¬å·®ç•°: {target_region} vs {part_region} (å…è¨±)")
                return True
            
            # å…¶ä»–ä¸æ˜ç¢ºçš„å·®ç•°çµ¦äºˆè­¦å‘Šä½†å…è¨±é€šé
            self.logger.info(f"âš ï¸ åœ°å€ä»£ç¢¼å·®ç•°: {target_region} vs {part_region} (å…è¨±ä½†éœ€æ³¨æ„)")
            return True
        
        # å¦‚æœä¸€å€‹æœ‰åœ°å€ä»£ç¢¼ï¼Œä¸€å€‹æ²’æœ‰ï¼Œå…è¨±é€šé
        self.logger.info(f"â„¹ï¸ åœ°å€ä»£ç¢¼å·®ç•°: {target_region} vs {part_region} (å…è¨±)")
        return True
    
    def _extract_region_code(self, model: str) -> str:
        """æå–åœ°å€ä»£ç¢¼"""
        import re
        
        # åŒ¹é…æœ€å¾Œçš„åœ°å€ä»£ç¢¼ (å¦‚ -A, -AU, -BE, -AE ç­‰)
        match = re.search(r'-([A-Z]{1,3})$', model.upper())
        if match:
            return match.group(1)
        return ""
    
    def _has_connector_mismatch(self, target_model: str, part_number: str, description: str) -> bool:
        """æª¢æŸ¥é€£æ¥å™¨é¡å‹æ˜¯å¦åŒ¹é…"""
        target_upper = target_model.upper()
        part_upper = part_number.upper()
        desc_lower = description.lower()
        
        # M12é€£æ¥å™¨æª¢æŸ¥
        target_has_m12 = 'M12' in target_upper
        part_has_m12 = 'M12' in part_upper or 'm12' in desc_lower
        
        if target_has_m12 != part_has_m12:
            self.logger.info(f"âš ï¸ M12é€£æ¥å™¨å·®ç•°: target={target_has_m12}, part={part_has_m12} (å…è¨±)")
            # æ”¹ç‚ºè­¦å‘Šè€Œéæ‹’çµ•ï¼Œå› ç‚ºæè¿°å¯èƒ½ä¸å®Œæ•´
            # return True è¡¨ç¤ºä¸æ‹’çµ•
        
        # å…‰çº–é€£æ¥å™¨æª¢æŸ¥ (F, FI, LX, SX)
        fiber_indicators = ['F-', 'FI-', 'LX-', 'SX-', 'G-', 'GI-']
        target_has_fiber = any(ind in target_upper for ind in fiber_indicators)
        part_has_fiber = any(ind in part_upper for ind in fiber_indicators) or 'fiber' in desc_lower
        
        if target_has_fiber != part_has_fiber:
            self.logger.info(f"âš ï¸ å…‰çº–é€£æ¥å™¨å·®ç•°: target={target_has_fiber}, part={part_has_fiber} (å…è¨±)")
            # æ”¹ç‚ºè­¦å‘Šè€Œéæ‹’çµ•
            
        return False
    
    def _has_function_mismatch(self, target_model: str, part_number: str, description: str) -> bool:
        """æª¢æŸ¥åŠŸèƒ½é¡å‹æ˜¯å¦åŒ¹é…"""
        target_upper = target_model.upper()
        part_upper = part_number.upper()
        desc_lower = description.lower()
        
        # GPI/GFPI åŠŸèƒ½æª¢æŸ¥ (PoEæ³¨å…¥å™¨)
        target_is_gpi = any(gpi in target_upper for gpi in ['GPI', 'GFPI'])
        part_is_gpi = any(gpi in part_upper for gpi in ['GPI', 'GFPI']) or 'injector' in desc_lower
        
        if target_is_gpi != part_is_gpi:
            # GPIåŠŸèƒ½å·®ç•°æ¯”è¼ƒé‡è¦ï¼Œå› ç‚ºé€™å½±éŸ¿ç”¢å“é¡å‹ (PoEæ³¨å…¥å™¨ vs äº¤æ›æ©Ÿ)
            self.logger.info(f"âŒ GPIåŠŸèƒ½ä¸åŒ¹é…: target={target_is_gpi}, part={part_is_gpi}")
            return True
        
        # ç®¡ç†åŠŸèƒ½æª¢æŸ¥ (M vs éM)
        target_is_managed = '-M-' in target_upper or target_upper.endswith('-M')
        part_is_managed = '-M-' in part_upper or part_upper.endswith('-M') or 'managed' in desc_lower
        
        # å°æ–¼ç®¡ç†åŠŸèƒ½ï¼Œå…è¨±ä¸€å®šéˆæ´»æ€§ï¼Œä½†è¨˜éŒ„å·®ç•°
        if target_is_managed != part_is_managed:
            self.logger.info(f"â„¹ï¸ ç®¡ç†åŠŸèƒ½å·®ç•°: target={target_is_managed}, part={part_is_managed}")
            # ä¸ä½œç‚ºå¦æ±ºæ¢ä»¶ï¼Œå› ç‚ºæè¿°å¯èƒ½ä¸å®Œæ•´
        
        return False
    
    def _is_valid_eccn_format(self, eccn_code: str) -> bool:
        """é©—è­‰ECCNä»£ç¢¼æ ¼å¼æ˜¯å¦æœ‰æ•ˆ"""
        if not eccn_code or not isinstance(eccn_code, str):
            return False
            
        eccn_code = eccn_code.strip().upper()
        
        # EAR99 æ˜¯æœ‰æ•ˆæ ¼å¼
        if eccn_code == 'EAR99':
            return True
            
        # æ¨™æº–ECCNæ ¼å¼ï¼šæ•¸å­—+å­—æ¯+3ä½æ•¸å­—ï¼Œå¯é¸å­åˆ†é¡
        # ä¾‹å¦‚ï¼š5A991, 5A991.b, 5A991.b.1, 4A994
        import re
        pattern = r'^[0-9][A-Z][0-9]{3}(?:\.[a-zA-Z](?:\.[0-9]+)?)?$'
        return bool(re.match(pattern, eccn_code))
    
    def _normalize_eccn_format(self, eccn_code: str) -> str:
        """æ¨™æº–åŒ–ECCNæ ¼å¼ï¼šå­åˆ†é¡å­—æ¯è½‰ç‚ºå°å¯«"""
        # EAR99 ä¿æŒä¸è®Š
        if eccn_code == 'EAR99':
            return eccn_code
            
        # å°æ–¼é¡ä¼¼ 5A992.C çš„æ ¼å¼ï¼Œå°‡å­åˆ†é¡å­—æ¯è½‰ç‚ºå°å¯«
        pattern = r'(\d[A-Z]\d{3})\.([A-Z])(\.\d+)?'
        match = re.match(pattern, eccn_code)
        if match:
            base = match.group(1)  # ä¾‹å¦‚ 5A992
            subcategory = match.group(2).lower()  # C -> c
            version = match.group(3) if match.group(3) else ''  # .1 æˆ–ç©º
            return f"{base}.{subcategory}{version}"
        
        # å¦‚æœæ ¼å¼ä¸åŒ¹é…ï¼Œè¿”å›åŸå§‹å€¼
        return eccn_code

    def enhance_classification(self, product_model: str, pdf_content: str, 
                             original_classification: Dict) -> Dict:
        """
        å¢å¼·åŸå§‹åˆ†é¡çµæœ
        """
        self.logger.info(f" é–‹å§‹å·¥å…·å¢å¼·åˆ†é¡: {product_model}")
        
        # åŸ·è¡Œäº¤å‰åƒè€ƒ
        cross_ref_result = self.cross_reference_eccn(product_model, pdf_content)
        
        # æ¯”è¼ƒåŸå§‹åˆ†é¡å’Œå·¥å…·å¢å¼·çµæœ
        original_eccn = original_classification.get('eccn_code', 'Unknown')
        external_eccn = cross_ref_result.get('eccn_code', 'Unknown')
        
        # æ±ºå®šæœ€çµ‚åˆ†é¡
        if cross_ref_result.get('confidence') == 'high' and external_eccn != original_eccn:
            # é«˜ä¿¡å¿ƒåº¦çš„å¤–éƒ¨ä¾†æºå„ªå…ˆ
            final_classification = cross_ref_result
            final_classification['validation_decision'] = 'external_override'
            final_classification['original_classification'] = original_classification
        elif cross_ref_result.get('confidence') in ['medium', 'high'] and external_eccn == original_eccn:
            # å¤–éƒ¨ä¾†æºç¢ºèªåŸå§‹åˆ†é¡
            final_classification = original_classification.copy()
            final_classification['confidence'] = 'high'  # æå‡ä¿¡å¿ƒåº¦
            final_classification['validation_decision'] = 'external_confirmation'
            final_classification['cross_reference_result'] = cross_ref_result
        else:
            # ä¿æŒåŸå§‹åˆ†é¡ä½†è¨˜éŒ„ä¸ä¸€è‡´
            final_classification = original_classification.copy()
            final_classification['validation_decision'] = 'original_maintained'
            final_classification['cross_reference_result'] = cross_ref_result
            final_classification['consistency_note'] = f'å¤–éƒ¨ä¾†æºå»ºè­°{external_eccn}ï¼Œä½†ä¿æŒåŸå§‹åˆ†é¡{original_eccn}'
        
        final_classification['tool_validation'] = True
        final_classification['validation_timestamp'] = datetime.now().isoformat()
        
        self.logger.info(f"âœ… å·¥å…·é©—è­‰å®Œæˆ: {final_classification.get('eccn_code')} (æ±ºç­–: {final_classification.get('validation_decision')})")
        
        return final_classification

# ä½¿ç”¨ç¤ºä¾‹
def example_usage():
    """ä½¿ç”¨ç¤ºä¾‹"""
    import logging
    
    # è¨­ç½®æ—¥èªŒ
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    
    # å‰µå»ºå·¥å…·å¢å¼·å™¨
    enhancer = ECCNToolEnhancer(logger)
    
    # æ¨¡æ“¬åŸå§‹åˆ†é¡çµæœ
    original_result = {
        'eccn_code': '5A991',
        'confidence': 'medium',
        'method': 'ai_classification',
        'reasoning': 'Industrial Ethernet switch with managed features'
    }
    
    # æ¨¡æ“¬PDFå…§å®¹
    pdf_content = """
    EKI-2528G Industrial Ethernet Switch
    24 Gigabit Ethernet ports + 4 Combo ports
    Operating Temperature: -40Â°C to 75Â°C
    Managed switch with VLAN support
    Industrial grade housing
    """
    
    # åŸ·è¡Œå·¥å…·å¢å¼·
    validated_result = enhancer.enhance_classification(
        product_model="EKI-2528G",
        pdf_content=pdf_content,
        original_classification=original_result
    )
    
    print(" å·¥å…·å¢å¼·çµæœ:")
    print(json.dumps(validated_result, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    example_usage()#!/usr/bin/env python3
"""
Mouser API æ•´åˆæ¨¡çµ„
æä¾›çœŸå¯¦çš„ Mouser Electronics API æ•´åˆåŠŸèƒ½
ç”¨æ–¼æŸ¥è©¢ç”¢å“çš„å®˜æ–¹ ECCN åˆ†é¡è³‡è¨Š
"""

import json
import requests
import re
import time
from typing import Dict, List, Optional, Any
import logging
from datetime import datetime

class MouserAPIClient:
    """Mouser Electronics API å®¢æˆ¶ç«¯ with Feature-Based Search"""
    
    def __init__(self, api_key: str = None, logger: logging.Logger = None):
        self.api_key = api_key or "d337cdb2-f839-4405-b34a-2533df7c60af"
        self.logger = logger or logging.getLogger(__name__)
        
        # Mouser API ç«¯é» (ä½¿ç”¨v1.0)
        self.base_url = "https://api.mouser.com"
        self.search_endpoint = f"{self.base_url}/api/v1.0/search/keyword"
        self.part_detail_endpoint = f"{self.base_url}/api/v1/search/partnumber"
        
        # API é…ç½®
        self.timeout = 30
        self.max_retries = 3
        self.rate_limit_delay = 1  # ç§’
        
        # è«‹æ±‚æ¨™é ­
        self.headers = {
            'accept': 'application/json',
            'Content-Type': 'application/json'
        }
            
        # ECCN æ¨¡å¼åŒ¹é…
        self.eccn_pattern = re.compile(r'\b(EAR99|[0-9][A-Z][0-9]{3}(?:\.[a-zA-Z](?:\.[0-9]+)?)?)\b')
        
        # PDFç‰¹å¾µæå–ç›¸é—œé…ç½®
        self.feature_keywords = {
            'management': ['snmp', 'web', 'gui', 'cli', 'management', 'managed', 'configuration', 'monitoring'],
            'switching': ['switch', 'ethernet', 'network', 'port', 'gigabit', 'switching', 'layer2', 'layer3'],
            'industrial': ['industrial', 'din-rail', 'rugged', 'wide temperature', 'harsh environment'],
            'protocols': ['modbus', 'profinet', 'tcp', 'ip', 'ethernet', 'bacnet', 'opcua'],
            'security': ['encryption', 'vpn', 'firewall', '802.1x', 'authentication', 'security', 'access control'],
            'performance': ['gigabit', '10g', 'switching capacity', 'throughput', 'wire-speed', 'backplane'],
            'quality': ['qos', 'vlan', 'link aggregation', 'lacp', 'spanning tree', 'multicast']
        }
    
    def _normalize_eccn_format(self, eccn_code: str) -> str:
        """æ¨™æº–åŒ–ECCNæ ¼å¼ï¼šå­åˆ†é¡å­—æ¯è½‰ç‚ºå°å¯«"""
        # EAR99 ä¿æŒä¸è®Š
        if eccn_code == 'EAR99':
            return eccn_code
            
        # å°æ–¼é¡ä¼¼ 5A992.C çš„æ ¼å¼ï¼Œå°‡å­åˆ†é¡å­—æ¯è½‰ç‚ºå°å¯«
        import re
        pattern = r'(\d[A-Z]\d{3})\.([A-Z])(\.\d+)?'
        match = re.match(pattern, eccn_code)
        if match:
            base = match.group(1)  # ä¾‹å¦‚ 5A992
            subcategory = match.group(2).lower()  # C -> c
            version = match.group(3) if match.group(3) else ''  # .1 æˆ–ç©º
            return f"{base}.{subcategory}{version}"
        
        # å¦‚æœæ ¼å¼ä¸åŒ¹é…ï¼Œè¿”å›åŸå§‹å€¼
        return eccn_code

    def search_by_keyword(self, keyword: str, max_results: int = 10) -> List[Dict]:
        """
        ä½¿ç”¨é—œéµå­—æœç´¢ç”¢å“ (v1.0 API)
        
        Args:
            keyword: æœç´¢é—œéµå­— (ç”¢å“å‹è™Ÿç­‰)
            max_results: æœ€å¤§çµæœæ•¸é‡
            
        Returns:
            ç”¢å“æ¸…å–®
        """
        try:
            self.logger.info(f" Mouseré—œéµå­—æœç´¢: {keyword}")
            
            # ä½¿ç”¨æŸ¥è©¢åƒæ•¸æ ¼å¼
            url = f"{self.search_endpoint}?apiKey={self.api_key}"
            
            payload = {
                "SearchByKeywordRequest": {
                    "keyword": keyword,
                    "records": min(max_results, 50),  # APIé™åˆ¶æœ€å¤š50å€‹çµæœ
                    "startingRecord": 0,
                    "searchOptions": "ExcludeNonBuyable,ExcludeObsolete",
                    "searchWithYourSignUpLanguage": "false"
                }
            }
            
            response = requests.post(
                url,
                headers=self.headers,
                json=payload,
                timeout=self.timeout
            )
            
            if response.status_code == 200:
                data = response.json()
                search_results = data.get('SearchResults', {})
                parts = search_results.get('Parts', [])
                
                self.logger.info(f" æ‰¾åˆ° {len(parts)} å€‹ç”¢å“")
                return parts
            else:
                self.logger.warning(f"APIå›æ‡‰éŒ¯èª¤: {response.status_code} - {response.text}")
                return []
            
        except Exception as e:
            self.logger.error(f" é—œéµå­—æœç´¢å¤±æ•—: {str(e)}")
            return []

    def search_by_part_number(self, part_number: str) -> Optional[Dict]:
        """
        ä½¿ç”¨ç²¾ç¢ºé›¶ä»¶è™Ÿæœç´¢ (v1.0 API)
        
        Args:
            part_number: ç²¾ç¢ºçš„é›¶ä»¶è™Ÿ
            
        Returns:
            ç”¢å“è©³æƒ…æˆ–None
        """
        try:
            self.logger.info(f" Mouseré›¶ä»¶è™Ÿæœç´¢: {part_number}")
            
            # ä½¿ç”¨æŸ¥è©¢åƒæ•¸æ ¼å¼
            url = f"{self.part_detail_endpoint}?apiKey={self.api_key}"
            
            payload = {
                "SearchByPartRequest": {
                    "mouserPartNumber": part_number,
                    "partSearchOptions": "ExcludeNonBuyable"
                }
            }
            
            response = requests.post(
                url,
                headers=self.headers,
                json=payload,
                timeout=self.timeout
            )
            
            if response.status_code == 200:
                data = response.json()
                search_results = data.get('SearchResults', {})
                parts = search_results.get('Parts', [])
                
                if parts:
                    self.logger.info(f" æ‰¾åˆ°é›¶ä»¶: {parts[0].get('MouserPartNumber', 'N/A')}")
                    return parts[0]
                else:
                    self.logger.info("ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„é›¶ä»¶")
                    return None
            else:
                self.logger.warning(f"APIå›æ‡‰éŒ¯èª¤: {response.status_code} - {response.text}")
                return None
            
        except Exception as e:
            self.logger.error(f" é›¶ä»¶è™Ÿæœç´¢å¤±æ•—: {str(e)}")
            return None

    def get_eccn_info(self, product_model: str, pdf_content: str = None) -> Optional[Dict]:
        """
        ç²å–ç”¢å“çš„ ECCN è³‡è¨Š (æ”¯æŒç‰¹å¾µåŒ¹é…æœç´¢)
        
        Args:
            product_model: ç”¢å“å‹è™Ÿ
            pdf_content: PDFå…§å®¹ (å¯é¸ï¼Œç”¨æ–¼ç‰¹å¾µåŒ¹é…)
            
        Returns:
            ECCN è³‡è¨Šå­—å…¸æˆ–None
        """
        try:
            self.logger.info(f" æŸ¥è©¢ECCN: {product_model}")
            
            # 1. å˜—è©¦ç²¾ç¢ºé›¶ä»¶è™Ÿæœç´¢
            exact_result = self.search_by_part_number(product_model)
            if exact_result:
                eccn_info = self._extract_eccn_from_part(exact_result, product_model)
                if eccn_info:
                    eccn_info['search_method'] = 'exact_part_number'
                    return eccn_info
            
            # 2. é—œéµå­—æœç´¢
            keyword_results = self.search_by_keyword(product_model, max_results=20)
            
            # å°‹æ‰¾æœ€ä½³åŒ¹é…
            best_match = self._find_best_match(keyword_results, product_model)
            if best_match:
                eccn_info = self._extract_eccn_from_part(best_match, product_model)
                if eccn_info:
                    eccn_info['search_method'] = 'keyword_search'
                    return eccn_info
            
            # 3. è®Šé«”æœç´¢ (ç§»é™¤å¸¸è¦‹å¾Œç¶´)
            variant_models = self._generate_model_variants(product_model)
            for variant in variant_models:
                variant_results = self.search_by_keyword(variant, max_results=10)
                for result in variant_results:
                    if self._is_model_similar(result.get('MouserPartNumber', ''), product_model):
                        eccn_info = self._extract_eccn_from_part(result, product_model)
                        if eccn_info:
                            eccn_info['search_method'] = 'variant_search'
                            eccn_info['variant_used'] = variant
                            return eccn_info
                time.sleep(self.rate_limit_delay)
            
            # 4. æ–°å¢ï¼šç‰¹å¾µåŒ¹é…æœç´¢ (ç•¶å‰è¿°æ–¹æ³•éƒ½å¤±æ•—æ™‚)
            if pdf_content:
                self.logger.info(" ä½¿ç”¨PDFç‰¹å¾µé€²è¡Œç›¸ä¼¼ç”¢å“æœç´¢...")
                feature_based_result = self.search_by_features(pdf_content, product_model)
                if feature_based_result:
                    return feature_based_result
            
            self.logger.warning(f"ï¸ æœªæ‰¾åˆ° {product_model} çš„ECCNè³‡è¨Š")
            return None
            
        except Exception as e:
            self.logger.error(f" ECCNæŸ¥è©¢å¤±æ•—: {str(e)}")
            return None

    def _make_request(self, url: str, payload: Dict) -> Optional[Dict]:
        """ç™¼é€APIè«‹æ±‚ä¸¦è™•ç†é‡è©¦"""
        
        for attempt in range(1, self.max_retries + 1):
            try:
                self.logger.debug(f"APIè«‹æ±‚å˜—è©¦ {attempt}/{self.max_retries}")
                
                response = requests.post(
                    url,
                    headers=self.headers,
                    json=payload,
                    timeout=self.timeout
                )
                
                # APIé‡‘é‘°æª¢æŸ¥
                if response.status_code == 401:
                    self.logger.error(" Mouser APIèªè­‰å¤±æ•— - è«‹æª¢æŸ¥APIé‡‘é‘°")
                    return None
                
                # é€Ÿç‡é™åˆ¶æª¢æŸ¥
                if response.status_code == 429:
                    self.logger.warning("ï¸ APIé€Ÿç‡é™åˆ¶ - ç­‰å¾…é‡è©¦")
                    time.sleep(self.rate_limit_delay * attempt)
                    continue
                
                if response.status_code == 200:
                    return response.json()
                else:
                    self.logger.warning(f"APIå›æ‡‰éŒ¯èª¤: {response.status_code} - {response.text}")
                    
            except requests.exceptions.Timeout:
                self.logger.warning(f"APIè«‹æ±‚è¶…æ™‚ (å˜—è©¦ {attempt}/{self.max_retries})")
            except Exception as e:
                self.logger.error(f"APIè«‹æ±‚ä¾‹å¤–: {str(e)}")
            
            if attempt < self.max_retries:
                time.sleep(self.rate_limit_delay * attempt)
        
        return None

    def _extract_eccn_from_part(self, part_data: Dict, original_model: str) -> Optional[Dict]:
        """å¾é›¶ä»¶è³‡æ–™ä¸­æå–ECCNè³‡è¨Š"""
        
        try:
            mouser_part_number = part_data.get('MouserPartNumber', '')
            manufacturer = part_data.get('Manufacturer', '')
            description = part_data.get('Description', '')
            
            # 1. æª¢æŸ¥ProductComplianceä¸­çš„ECCN (æ­£ç¢ºçš„APIæ ¼å¼)
            compliance = part_data.get('ProductCompliance', [])
            for comp in compliance:
                if comp.get('ComplianceName') == 'ECCN':
                    eccn_number = comp.get('ComplianceValue', '')
                    if eccn_number and eccn_number not in ['N/A', 'Not Available', '', 'TBD']:
                        # é©—è­‰ECCNæ ¼å¼
                        if self.eccn_pattern.match(eccn_number):
                            # æ¨™æº–åŒ–ECCNæ ¼å¼ï¼šå­åˆ†é¡å­—æ¯è½‰ç‚ºå°å¯«
                            normalized_eccn = self._normalize_eccn_format(eccn_number)
                            confidence = self._calculate_confidence(part_data, original_model)
                            
                            return {
                                'source': 'mouser_api',
                                'eccn_code': normalized_eccn,
                                'mouser_part_number': mouser_part_number,
                                'manufacturer': manufacturer,
                                'product_description': description,
                                'confidence': confidence,
                                'match_score': self._calculate_match_score(mouser_part_number, original_model),
                                'raw_data': part_data,
                                'timestamp': datetime.now().isoformat()
                            }
            
            # 2. å‚™ç”¨ï¼šæª¢æŸ¥èˆŠæ ¼å¼çš„ECCNæ¬„ä½
            eccn_number = part_data.get('ExportControlClassificationNumber', '')
            eccn_description = part_data.get('ExportControlClassificationNumberDescription', '')
            
            if eccn_number and eccn_number not in ['N/A', 'Not Available', '', 'TBD']:
                if self.eccn_pattern.match(eccn_number):
                    # æ¨™æº–åŒ–ECCNæ ¼å¼
                    normalized_eccn = self._normalize_eccn_format(eccn_number)
                    confidence = self._calculate_confidence(part_data, original_model)
                    
                    return {
                        'source': 'mouser_api',
                        'eccn_code': normalized_eccn,
                        'eccn_description': eccn_description,
                        'mouser_part_number': mouser_part_number,
                        'manufacturer': manufacturer,
                        'product_description': description,
                        'confidence': confidence,
                        'match_score': self._calculate_match_score(mouser_part_number, original_model),
                        'raw_data': part_data,
                        'timestamp': datetime.now().isoformat()
                    }
            
            # 3. æœ€å¾Œå˜—è©¦ï¼šæª¢æŸ¥æè¿°ä¸­çš„ECCNæ¨¡å¼
            combined_text = f"{description} {eccn_description}".upper()
            eccn_matches = self.eccn_pattern.findall(combined_text)
            
            if eccn_matches:
                # æ¨™æº–åŒ–ECCNæ ¼å¼
                normalized_eccn = self._normalize_eccn_format(eccn_matches[0])
                return {
                    'source': 'mouser_api_extracted',
                    'eccn_code': normalized_eccn,
                    'mouser_part_number': mouser_part_number,
                    'manufacturer': manufacturer,
                    'product_description': description,
                    'confidence': 'medium',
                    'extraction_method': 'text_pattern',
                    'raw_data': part_data,
                    'timestamp': datetime.now().isoformat()
                }
            
            return None
            
        except Exception as e:
            self.logger.error(f"ECCNæå–å¤±æ•—: {str(e)}")
            return None

    def _find_best_match(self, parts: List[Dict], target_model: str) -> Optional[Dict]:
        """åœ¨æœç´¢çµæœä¸­æ‰¾åˆ°æœ€ä½³åŒ¹é…"""
        
        if not parts:
            return None
        
        scored_parts = []
        
        for part in parts:
            mouser_pn = part.get('MouserPartNumber', '')
            manufacturer_pn = part.get('ManufacturerPartNumber', '')
            
            # è¨ˆç®—åŒ¹é…åˆ†æ•¸
            score = max(
                self._calculate_match_score(mouser_pn, target_model),
                self._calculate_match_score(manufacturer_pn, target_model)
            )
            
            if score > 0.5:  # åªè€ƒæ…®ç›¸é—œæ€§è¼ƒé«˜çš„çµæœ
                scored_parts.append((part, score))
        
        if scored_parts:
            # æŒ‰åˆ†æ•¸æ’åºä¸¦è¿”å›æœ€ä½³åŒ¹é…
            scored_parts.sort(key=lambda x: x[1], reverse=True)
            return scored_parts[0][0]
        
        return None

    def _calculate_match_score(self, api_model: str, target_model: str) -> float:
        """è¨ˆç®—å‹è™ŸåŒ¹é…åˆ†æ•¸ (0-1)"""
        
        if not api_model or not target_model:
            return 0.0
        
        # æ¨™æº–åŒ–å­—ä¸²
        api_clean = re.sub(r'[-_\s]', '', api_model.upper())
        target_clean = re.sub(r'[-_\s]', '', target_model.upper())
        
        # ç²¾ç¢ºåŒ¹é…
        if api_clean == target_clean:
            return 1.0
        
        # åŒ…å«åŒ¹é…
        if target_clean in api_clean or api_clean in target_clean:
            return 0.8
        
        # å­—é¦–åŒ¹é…
        if api_clean.startswith(target_clean) or target_clean.startswith(api_clean):
            return 0.7
        
        # ç›¸ä¼¼åº¦è¨ˆç®— (ç°¡åŒ–ç‰ˆæœ¬)
        common_chars = sum(1 for a, b in zip(api_clean, target_clean) if a == b)
        max_len = max(len(api_clean), len(target_clean))
        
        if max_len > 0:
            similarity = common_chars / max_len
            return similarity * 0.6  # é™ä½æ¬Šé‡
        
        return 0.0

    def _calculate_confidence(self, part_data: Dict, original_model: str) -> str:
        """è¨ˆç®—ECCNè³‡è¨Šçš„å¯ä¿¡åº¦"""
        
        confidence_score = 0
        
        # ECCNè³‡æ–™å®Œæ•´æ€§
        if part_data.get('ExportControlClassificationNumber'):
            confidence_score += 3
        if part_data.get('ExportControlClassificationNumberDescription'):
            confidence_score += 2
        
        # å‹è™ŸåŒ¹é…åº¦
        mouser_pn = part_data.get('MouserPartNumber', '')
        manufacturer_pn = part_data.get('ManufacturerPartNumber', '')
        
        match_score = max(
            self._calculate_match_score(mouser_pn, original_model),
            self._calculate_match_score(manufacturer_pn, original_model)
        )
        
        if match_score >= 0.9:
            confidence_score += 3
        elif match_score >= 0.7:
            confidence_score += 2
        elif match_score >= 0.5:
            confidence_score += 1
        
        # è£½é€ å•†è³‡è¨Š
        if part_data.get('Manufacturer'):
            confidence_score += 1
        
        # ç”¢å“ç‹€æ…‹
        if part_data.get('ProductStatus') == 'Active':
            confidence_score += 1
        
        # è½‰æ›ç‚ºä¿¡å¿ƒç­‰ç´š
        if confidence_score >= 7:
            return 'high'
        elif confidence_score >= 4:
            return 'medium'
        else:
            return 'low'

    def _generate_model_variants(self, model: str) -> List[str]:
        """ç”Ÿæˆå‹è™Ÿè®Šé«”ç”¨æ–¼æœç´¢"""
        
        variants = []
        
        # ç§»é™¤å¸¸è¦‹å¾Œç¶´
        suffixes_to_remove = ['-AE', '-BE', '-MI', '-ST', '-CA', '/US', '/EU', '/JP']
        
        for suffix in suffixes_to_remove:
            if model.endswith(suffix):
                variants.append(model[:-len(suffix)])
        
        # ç§»é™¤æœ€å¾Œçš„å­—å…ƒ (å¯èƒ½æ˜¯ç‰ˆæœ¬è™Ÿ)
        if len(model) > 3:
            variants.append(model[:-1])
            variants.append(model[:-2])
        
        # åŸºç¤å‹è™Ÿ (ç§»é™¤æ•¸å­—å¾Œç¶´)
        base_match = re.match(r'([A-Z]+-?\d+)', model)
        if base_match:
            variants.append(base_match.group(1))
        
        return list(set(variants))  # å»é‡

    def _is_model_similar(self, api_model: str, target_model: str) -> bool:
        """æª¢æŸ¥å‹è™Ÿæ˜¯å¦ç›¸ä¼¼"""
        return self._calculate_match_score(api_model, target_model) >= 0.6
    
    def extract_pdf_features(self, pdf_content: str) -> Dict[str, Any]:
        """
        å¾PDFå…§å®¹ä¸­æå–ç”¢å“ç‰¹å¾µç”¨æ–¼ç›¸ä¼¼ç”¢å“æœç´¢
        
        Args:
            pdf_content: PDFæ–‡æœ¬å…§å®¹
            
        Returns:
            ç‰¹å¾µå­—å…¸
        """
        try:
            self.logger.info(" æå–PDFç”¢å“ç‰¹å¾µ...")
            
            content_lower = pdf_content.lower()
            features = {
                'feature_scores': {},
                'technical_specs': {},
                'search_keywords': []
            }
            
            # 1. è¨ˆç®—å„é¡ç‰¹å¾µçš„åˆ†æ•¸
            for category, keywords in self.feature_keywords.items():
                score = 0
                matched_keywords = []
                
                for keyword in keywords:
                    if keyword in content_lower:
                        score += 1
                        matched_keywords.append(keyword)
                
                features['feature_scores'][category] = {
                    'score': score,
                    'matched_keywords': matched_keywords,
                    'normalized_score': score / len(keywords) if keywords else 0
                }
            
            # 2. æå–æŠ€è¡“è¦æ ¼
            features['technical_specs'] = self._extract_technical_specs(content_lower)
            
            # 3. ç”Ÿæˆæœç´¢é—œéµå­—
            features['search_keywords'] = self._generate_search_keywords(features)
            
            # 4. ç¢ºå®šç”¢å“é¡å‹
            features['product_type'] = self._determine_product_type(features)
            
            self.logger.info(f" ç‰¹å¾µæå–å®Œæˆï¼Œç”¢å“é¡å‹: {features['product_type']}")
            return features
            
        except Exception as e:
            self.logger.error(f" PDFç‰¹å¾µæå–å¤±æ•—: {str(e)}")
            return {}
    
    def _extract_technical_specs(self, content_lower: str) -> Dict[str, Any]:
        """æå–æŠ€è¡“è¦æ ¼"""
        specs = {}
        
        # æº«åº¦ç¯„åœ
        temp_pattern = r'operating temperature[:\s]*(-?\d+)[^\d]*(-?\d+)'
        temp_match = re.search(temp_pattern, content_lower)
        if temp_match:
            specs['temp_min'] = int(temp_match.group(1))
            specs['temp_max'] = int(temp_match.group(2))
        
        # é›»æºè¦æ ¼
        if 'dc power' in content_lower or '12v' in content_lower or '24v' in content_lower:
            specs['power_type'] = 'dc'
        elif '100-240v' in content_lower or 'ac power' in content_lower:
            specs['power_type'] = 'ac'
        
        # ç«¯å£æ•¸é‡
        port_pattern = r'(\d+)[^\d]*port'
        port_matches = re.findall(port_pattern, content_lower)
        if port_matches:
            specs['port_count'] = max(int(p) for p in port_matches)
        
        # åˆ‡æ›å®¹é‡
        capacity_pattern = r'switching capacity[:\s]*(\d+)[^\d]*gbps'
        capacity_match = re.search(capacity_pattern, content_lower)
        if capacity_match:
            specs['switching_capacity_gbps'] = int(capacity_match.group(1))
        
        return specs
    
    def _generate_search_keywords(self, features: Dict) -> List[str]:
        """åŸºæ–¼ç‰¹å¾µç”Ÿæˆæœç´¢é—œéµå­—"""
        keywords = []
        
        # åŸºæ–¼ç‰¹å¾µåˆ†æ•¸ç”Ÿæˆé—œéµå­—
        for category, data in features['feature_scores'].items():
            if data['normalized_score'] > 0.3:  # é«˜åˆ†ç‰¹å¾µ
                keywords.extend(data['matched_keywords'][:3])  # å–å‰3å€‹é—œéµå­—
        
        # æŠ€è¡“è¦æ ¼é—œéµå­—
        specs = features['technical_specs']
        if 'power_type' in specs:
            keywords.append(f"{specs['power_type']} power")
        
        if 'port_count' in specs:
            keywords.append(f"{specs['port_count']} port")
        
        # å»é‡ä¸¦è¿”å›å‰10å€‹æœ€ç›¸é—œçš„é—œéµå­—
        return list(dict.fromkeys(keywords))[:10]
    
    def _determine_product_type(self, features: Dict) -> str:
        """æ ¹æ“šç‰¹å¾µç¢ºå®šç”¢å“é¡å‹"""
        scores = features['feature_scores']
        
        # ç®¡ç†å‹äº¤æ›æ©ŸæŒ‡æ¨™
        if (scores.get('management', {}).get('normalized_score', 0) > 0.4 and
            scores.get('switching', {}).get('normalized_score', 0) > 0.3 and
            scores.get('quality', {}).get('normalized_score', 0) > 0.3):
            return 'managed_switch'
        
        # å·¥æ¥­ç´šäº¤æ›æ©ŸæŒ‡æ¨™
        elif (scores.get('switching', {}).get('normalized_score', 0) > 0.3 and
              scores.get('industrial', {}).get('normalized_score', 0) > 0.2):
            return 'industrial_switch'
        
        # åŸºæœ¬äº¤æ›æ©Ÿ
        elif scores.get('switching', {}).get('normalized_score', 0) > 0.3:
            return 'basic_switch'
        
        # ç¶²è·¯è¨­å‚™
        elif scores.get('switching', {}).get('normalized_score', 0) > 0.1:
            return 'network_equipment'
        
        return 'unknown'
    
    def search_by_features(self, pdf_content: str, original_model: str) -> Optional[Dict]:
        """
        åŸºæ–¼PDFç‰¹å¾µæœç´¢ç›¸ä¼¼ç”¢å“ä¸¦èšåˆECCN
        
        Args:
            pdf_content: PDFå…§å®¹
            original_model: åŸå§‹ç”¢å“å‹è™Ÿ
            
        Returns:
            èšåˆçš„ECCNè³‡è¨Šæˆ–None
        """
        try:
            # 1. æå–ç‰¹å¾µ
            features = self.extract_pdf_features(pdf_content)
            if not features:
                return None
            
            # 2. åŸºæ–¼ç‰¹å¾µæœç´¢ç›¸ä¼¼ç”¢å“
            similar_products = self._search_similar_products(features)
            if not similar_products:
                self.logger.info(" æœªæ‰¾åˆ°ç›¸ä¼¼ç”¢å“")
                return None
            
            # 3. æå–ECCNä¸¦é€²è¡Œèšåˆåˆ†æ
            eccn_analysis = self._analyze_similar_products_eccn(similar_products, features)
            if not eccn_analysis:
                return None
            
            # 4. ç”ŸæˆåŸºæ–¼ç‰¹å¾µçš„ECCNå»ºè­°
            return {
                'source': 'mouser_feature_matching',
                'eccn_code': eccn_analysis['recommended_eccn'],
                'confidence': eccn_analysis['confidence'],
                'reasoning': eccn_analysis['reasoning'],
                'search_method': 'feature_matching',
                'feature_analysis': features,
                'similar_products_count': len(similar_products),
                'eccn_distribution': eccn_analysis['eccn_distribution'],
                'matching_features': eccn_analysis['key_features'],
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f" ç‰¹å¾µåŒ¹é…æœç´¢å¤±æ•—: {str(e)}")
            return None
    
    def _search_similar_products(self, features: Dict) -> List[Dict]:
        """åŸºæ–¼ç‰¹å¾µæœç´¢ç›¸ä¼¼ç”¢å“"""
        similar_products = []
        
        try:
            # ä½¿ç”¨æœç´¢é—œéµå­—çµ„åˆæœç´¢
            search_keywords = features['search_keywords']
            product_type = features['product_type']
            
            # æ§‹å»ºæœç´¢æŸ¥è©¢
            search_queries = []
            
            if product_type == 'managed_switch':
                search_queries = [
                    'managed ethernet switch',
                    'industrial managed switch',
                    'layer 2 managed switch'
                ]
            elif product_type == 'industrial_switch':
                search_queries = [
                    'industrial ethernet switch',
                    'din rail ethernet switch',
                    'rugged ethernet switch'
                ]
            else:
                search_queries = [
                    'ethernet switch',
                    'network switch',
                    'industrial network'
                ]
            
            # å°æ¯å€‹æŸ¥è©¢åŸ·è¡Œæœç´¢
            for query in search_queries[:2]:  # é™åˆ¶æœç´¢æ¬¡æ•¸
                self.logger.info(f" æœç´¢æŸ¥è©¢: {query}")
                results = self.search_by_keyword(query, max_results=15)
                
                # éæ¿¾ç›¸é—œç”¢å“
                relevant_products = self._filter_relevant_products(results, features)
                similar_products.extend(relevant_products)
                
                time.sleep(self.rate_limit_delay)
            
            # å»é‡ä¸¦é™åˆ¶æ•¸é‡
            unique_products = []
            seen_parts = set()
            
            for product in similar_products:
                part_number = product.get('MouserPartNumber', '')
                if part_number and part_number not in seen_parts:
                    seen_parts.add(part_number)
                    unique_products.append(product)
                    
                    if len(unique_products) >= 20:  # é™åˆ¶æœ€å¤š20å€‹ç”¢å“
                        break
            
            self.logger.info(f" æ‰¾åˆ° {len(unique_products)} å€‹ç›¸ä¼¼ç”¢å“")
            return unique_products
            
        except Exception as e:
            self.logger.error(f" ç›¸ä¼¼ç”¢å“æœç´¢å¤±æ•—: {str(e)}")
            return []
    
    def _filter_relevant_products(self, products: List[Dict], features: Dict) -> List[Dict]:
        """éæ¿¾ç›¸é—œç”¢å“"""
        relevant_products = []
        
        for product in products:
            description = product.get('Description', '').lower()
            manufacturer = product.get('Manufacturer', '').lower()
            
            # åŸºæœ¬ç›¸é—œæ€§æª¢æŸ¥
            relevance_score = 0
            
            # æª¢æŸ¥ç”¢å“æè¿°ä¸­çš„é—œéµç‰¹å¾µ
            for category, data in features['feature_scores'].items():
                for keyword in data['matched_keywords']:
                    if keyword in description:
                        relevance_score += 1
            
            # å¦‚æœç›¸é—œæ€§åˆ†æ•¸è¶³å¤ é«˜ï¼ŒåŠ å…¥å€™é¸ (é™ä½é–€æª»)
            if relevance_score >= 1:  # é™ä½é–€æª»å¾2åˆ°1
                relevant_products.append(product)
        
        return relevant_products
    
    def _analyze_similar_products_eccn(self, products: List[Dict], features: Dict) -> Optional[Dict]:
        """åˆ†æç›¸ä¼¼ç”¢å“çš„ECCNåˆ†ä½ˆä¸¦æ¨è–¦"""
        try:
            eccn_data = []
            
            # æå–æ¯å€‹ç”¢å“çš„ECCN
            for product in products:
                eccn_info = self._extract_eccn_from_part(product, 'similar')
                if eccn_info and eccn_info.get('eccn_code'):
                    eccn_data.append({
                        'eccn_code': eccn_info['eccn_code'],
                        'product': product,
                        'confidence': eccn_info.get('confidence', 'medium')
                    })
            
            if not eccn_data:
                return None
            
            # çµ±è¨ˆECCNåˆ†ä½ˆ
            eccn_counts = {}
            for item in eccn_data:
                eccn = item['eccn_code']
                if eccn not in eccn_counts:
                    eccn_counts[eccn] = []
                eccn_counts[eccn].append(item)
            
            # æ™ºèƒ½ECCNæ¨è–¦ï¼šçµåˆå¤šæ•¸æ±ºç­–å’ŒæŠ€è¡“è¤‡é›œåº¦
            eccn_scores = self._calculate_eccn_scores(eccn_counts, features)
            
            # æ‰¾å‡ºå¾—åˆ†æœ€é«˜çš„ECCN
            recommended_eccn = max(eccn_scores.keys(), key=lambda x: eccn_scores[x]['final_score'])
            eccn_details = eccn_scores[recommended_eccn]
            
            count = eccn_details['count']
            total = len(eccn_data)
            percentage = (count / total) * 100
            
            # ç¢ºå®šä¿¡å¿ƒåº¦ï¼ˆåŸºæ–¼æœ€çµ‚å¾—åˆ†ï¼‰
            final_score = eccn_details['final_score']
            if final_score >= 80:
                confidence = 'high'
            elif final_score >= 60:
                confidence = 'medium'
            else:
                confidence = 'low'
            
            # ç”Ÿæˆæ¨ç†èªªæ˜
            spec_bonus = eccn_details.get('specification_bonus', 0)
            feature_match = eccn_details.get('feature_match_score', 0)
            
            if spec_bonus > 0:
                reasoning = f"åŸºæ–¼{total}å€‹ç›¸ä¼¼ç”¢å“åˆ†æï¼Œ{count}å€‹ç”¢å“({percentage:.1f}%)å…·æœ‰{recommended_eccn}åˆ†é¡ï¼Œè¦æ ¼æ¥è¿‘åº¦è©•åˆ¤+{spec_bonus}åˆ†(ç‰¹å¾µåŒ¹é…åº¦:{feature_match:.1f})"
            else:
                reasoning = f"åŸºæ–¼{total}å€‹ç›¸ä¼¼ç”¢å“åˆ†æï¼Œ{count}å€‹ç”¢å“({percentage:.1f}%)å…·æœ‰{recommended_eccn}åˆ†é¡"
            
            # è­˜åˆ¥é—œéµç‰¹å¾µ
            key_features = []
            product_type = features.get('product_type', 'unknown')
            if product_type == 'managed_switch':
                key_features = ['ç®¡ç†åŠŸèƒ½', 'é«˜ç´šç‰¹æ€§']
            elif product_type == 'industrial_switch':
                key_features = ['å·¥æ¥­ç´šè¨­è¨ˆ', 'å¯¬æº«ç¯„åœ']
            
            return {
                'recommended_eccn': recommended_eccn,
                'confidence': confidence,
                'reasoning': reasoning,
                'eccn_distribution': {eccn: len(products) for eccn, products in eccn_counts.items()},
                'key_features': key_features,
                'total_products_analyzed': total,
                'eccn_scores': eccn_scores  # æ·»åŠ è©³ç´°è©•åˆ†ä¿¡æ¯
            }
            
        except Exception as e:
            self.logger.error(f" ECCNåˆ†æå¤±æ•—: {str(e)}")
            return None

    def _calculate_eccn_scores(self, eccn_counts: Dict[str, List], features: Dict) -> Dict[str, Dict]:
        """
        åŸºæ–¼è¦æ ¼æ¥è¿‘åº¦è¨ˆç®—ECCNè©•åˆ†
        ä½¿ç”¨æŠ€è¡“ç‰¹å¾µåŒ¹é…æ›¿ä»£ç°¡å–®å¤šæ•¸æ±ºç­–
        """
        try:
            self.logger.info("ğŸ§® è¨ˆç®—åŸºæ–¼è¦æ ¼æ¥è¿‘åº¦çš„ECCNè©•åˆ†...")
            
            eccn_scores = {}
            
            # å®šç¾©ECCNæŠ€è¡“ç‰¹å¾µæ¬Šé‡è¡¨
            eccn_feature_profiles = {
                'EAR99': {
                    'management': 0.1,    # åŸºæœ¬ç®¡ç†åŠŸèƒ½
                    'security': 0.0,      # ç„¡å®‰å…¨åŠŸèƒ½
                    'performance': 0.2,   # åŸºæœ¬æ€§èƒ½
                    'protocols': 0.1,     # åŸºæœ¬å”è­°
                    'industrial': 0.0,    # éå·¥æ¥­ç´š
                    'quality': 0.1        # åŸºæœ¬QoS
                },
                '5A991': {
                    'management': 0.5,    # ä¸­ç­‰ç®¡ç†åŠŸèƒ½
                    'security': 0.2,      # åŸºæœ¬å®‰å…¨åŠŸèƒ½
                    'performance': 0.4,   # ä¸­ç­‰æ€§èƒ½
                    'protocols': 0.4,     # æ¨™æº–å”è­°æ”¯æ´
                    'industrial': 0.6,    # å·¥æ¥­ç´šè¨­è¨ˆ
                    'quality': 0.3        # æ¨™æº–QoS
                },
                '5A991.b': {
                    'management': 0.7,    # é«˜ç´šç®¡ç†åŠŸèƒ½
                    'security': 0.8,      # é«˜ç´šå®‰å…¨åŠŸèƒ½
                    'performance': 0.6,   # é«˜æ€§èƒ½
                    'protocols': 0.6,     # é«˜ç´šå”è­°æ”¯æ´
                    'industrial': 0.7,    # å¼·åŒ–å·¥æ¥­ç´š
                    'quality': 0.7        # é«˜ç´šQoS
                },
                '5A991.b.1': {
                    'management': 0.8,    # ä¼æ¥­ç´šç®¡ç†
                    'security': 0.6,      # ä¼æ¥­å®‰å…¨
                    'performance': 0.9,   # é«˜é€Ÿæ€§èƒ½
                    'protocols': 0.7,     # é«˜é€Ÿå”è­°
                    'industrial': 0.6,    # é©åº¦å·¥æ¥­åŒ–
                    'quality': 0.8        # ä¼æ¥­QoS
                },
                '4A994': {
                    'management': 0.9,    # å°ˆæ¥­ç®¡ç†åŠŸèƒ½
                    'security': 0.4,      # ä¸­ç­‰å®‰å…¨
                    'performance': 0.5,   # ä¸­ç­‰æ€§èƒ½
                    'protocols': 0.8,     # ç®¡ç†å”è­°å°ˆç²¾
                    'industrial': 0.5,    # éƒ¨åˆ†å·¥æ¥­åŒ–
                    'quality': 0.6        # ç®¡ç†å°å‘QoS
                },
                '5A992.c': {
                    'management': 0.9,    # ç¶œåˆç®¡ç†åŠŸèƒ½
                    'security': 0.9,      # æœ€é«˜å®‰å…¨åŠŸèƒ½
                    'performance': 0.8,   # é«˜ç«¯æ€§èƒ½
                    'protocols': 0.9,     # ç¶œåˆå”è­°æ”¯æ´
                    'industrial': 0.8,    # é«˜éšå·¥æ¥­ç´š
                    'quality': 0.9        # æœ€é«˜ç´šQoS
                }
            }
            
            # ç²å–ç›®æ¨™ç”¢å“çš„ç‰¹å¾µè©•åˆ†
            target_features = features.get('feature_scores', {})
            
            # å°æ¯å€‹ECCNè¨ˆç®—è©•åˆ†
            for eccn_code, products_list in eccn_counts.items():
                base_count = len(products_list)
                base_score = base_count * 10  # åŸºç¤åˆ†æ•¸ï¼šæ¯å€‹ç”¢å“10åˆ†
                
                # ç²å–è©²ECCNçš„ç‰¹å¾µé…ç½®
                feature_profile = eccn_feature_profiles.get(eccn_code, {})
                
                # è¨ˆç®—ç‰¹å¾µåŒ¹é…åº¦è©•åˆ†
                feature_match_score = 0.0
                matched_features = []
                
                for feature_category, target_data in target_features.items():
                    if feature_category in feature_profile:
                        target_score = target_data.get('normalized_score', 0)
                        expected_score = feature_profile[feature_category]
                        
                        # è¨ˆç®—åŒ¹é…åº¦ (1 - å·®è·çš„çµ•å°å€¼)
                        match_quality = 1.0 - abs(target_score - expected_score)
                        feature_match_score += match_quality * 10  # æ¯å€‹ç‰¹å¾µæœ€å¤š10åˆ†
                        
                        if match_quality > 0.7:  # é«˜åŒ¹é…åº¦
                            matched_features.append(f"{feature_category}({match_quality:.2f})")
                
                # è¦æ ¼æ¥è¿‘åº¦é¡å¤–çå‹µ
                specification_bonus = 0
                
                # æ ¹æ“šç‰¹å¾µåŒ¹é…åº¦çµ¦äºˆè¦æ ¼çå‹µï¼ˆé€šç”¨é‚è¼¯ï¼Œç„¡ç‰¹å®šå‹è™Ÿè™•ç†ï¼‰
                # è¨ˆç®—æ•´é«”ç‰¹å¾µè¤‡é›œåº¦åˆ†æ•¸
                total_feature_score = sum(
                    target_features.get(category, {}).get('normalized_score', 0) 
                    for category in ['management', 'security', 'protocols', 'quality', 'performance', 'industrial']
                ) / 6.0  # å¹³å‡åˆ†æ•¸
                
                # æ ¹æ“šECCNç´šåˆ¥å’Œç‰¹å¾µè¤‡é›œåº¦è¨ˆç®—è¦æ ¼çå‹µ
                eccn_complexity_weights = {
                    'EAR99': 0.1,
                    '5A991': 0.4,
                    '5A991.b': 0.7,
                    '5A991.b.1': 0.8,
                    '4A994': 0.6,
                    '5A992.c': 0.9
                }
                
                expected_complexity = eccn_complexity_weights.get(eccn_code, 0.5)
                complexity_match = 1.0 - abs(total_feature_score - expected_complexity)
                
                if complexity_match > 0.7:  # é«˜åŒ¹é…åº¦
                    specification_bonus = int(complexity_match * 50)  # æœ€é«˜50åˆ†çå‹µ
                    self.logger.info(f"ğŸ“Š {eccn_code}ç‰¹å¾µè¤‡é›œåº¦åŒ¹é…({complexity_match:.2f})ï¼Œç²å¾—è¦æ ¼çå‹µ: +{specification_bonus}")
                elif complexity_match > 0.5:  # ä¸­ç­‰åŒ¹é…åº¦
                    specification_bonus = int(complexity_match * 25)  # æœ€é«˜25åˆ†çå‹µ
                
                # è¨ˆç®—æœ€çµ‚è©•åˆ†
                final_score = base_score + feature_match_score + specification_bonus
                
                eccn_scores[eccn_code] = {
                    'count': base_count,
                    'base_score': base_score,
                    'feature_match_score': feature_match_score,
                    'specification_bonus': specification_bonus,
                    'final_score': final_score,
                    'matched_features': matched_features,
                    'feature_profile_match': {
                        category: {
                            'target': target_features.get(category, {}).get('normalized_score', 0),
                            'expected': feature_profile.get(category, 0),
                            'match_quality': 1.0 - abs(target_features.get(category, {}).get('normalized_score', 0) - feature_profile.get(category, 0))
                        }
                        for category in feature_profile.keys()
                    }
                }
                
                self.logger.info(f"ğŸ“Š {eccn_code}: åŸºç¤({base_score}) + ç‰¹å¾µåŒ¹é…({feature_match_score:.1f}) + è¦æ ¼çå‹µ({specification_bonus}) = {final_score:.1f}")
            
            return eccn_scores
            
        except Exception as e:
            self.logger.error(f" ECCNè©•åˆ†è¨ˆç®—å¤±æ•—: {str(e)}")
            return {}

# ä½¿ç”¨ç¤ºä¾‹å’Œæ¸¬è©¦
def test_mouser_api():
    """æ¸¬è©¦Mouser APIåŠŸèƒ½"""
    
    # è¨­ç½®æ—¥èªŒ
    import logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    
    # å‰µå»ºå®¢æˆ¶ç«¯ (ç„¡APIé‡‘é‘°æ™‚æœƒä½¿ç”¨å…¬é–‹ç«¯é»)
    client = MouserAPIClient(api_key=None, logger=logger)
    
    # æ¸¬è©¦ç”¢å“
    test_models = [
        "EKI-2428G-4CA-AE",
        "EKI-5525I-AE", 
        "TN-5510A-2L",
        "TN-4500A-T"
    ]
    
    print(" Mouser API æ¸¬è©¦")
    print("=" * 50)
    
    for model in test_models:
        print(f"\n æ¸¬è©¦å‹è™Ÿ: {model}")
        
        eccn_info = client.get_eccn_info(model)
        
        if eccn_info:
            print(f" ECCN: {eccn_info.get('eccn_code', 'N/A')}")
            print(f"   ä¿¡å¿ƒåº¦: {eccn_info.get('confidence', 'unknown')}")
            print(f"   æœç´¢æ–¹æ³•: {eccn_info.get('search_method', 'unknown')}")
            print(f"   è£½é€ å•†: {eccn_info.get('manufacturer', 'N/A')}")
        else:
            print(" æœªæ‰¾åˆ°ECCNè³‡è¨Š")
        
        time.sleep(2)  # é¿å…APIé€Ÿç‡é™åˆ¶

if __name__ == "__main__":
    test_mouser_api()#!/usr/bin/env python3
"""
WebSearch æ•´åˆæ¨¡çµ„
æä¾›ECCNç›¸é—œçš„ç¶²è·¯æœç´¢åŠŸèƒ½
åŒ…å«å®˜æ–¹æ³•è¦ã€å•†æ¥­è³‡æ–™åº«ã€æŠ€è¡“æ–‡æª”æœç´¢
"""

import json
import requests
import re
import time
from typing import Dict, List, Optional, Any
import logging
from datetime import datetime
from urllib.parse import quote, urljoin
import html

class ECCNWebSearcher:
    """ECCNç¶²è·¯æœç´¢å™¨"""
    
    def __init__(self, logger: logging.Logger = None):
        self.logger = logger or logging.getLogger(__name__)
        
        # æœç´¢é…ç½®
        self.timeout = 30
        self.max_results_per_query = 10
        self.rate_limit_delay = 1
        
        # ECCN ç›¸é—œé—œéµå­—å’Œæ¨¡å¼
        self.eccn_pattern = re.compile(r'\b(EAR99|[0-9][A-Z][0-9]{3}(?:\.[a-z](?:\.[0-9]+)?)?)\b', re.IGNORECASE)
        
        # å®˜æ–¹å’Œæ¬Šå¨ä¾†æºç¶²åŸŸ
        self.authoritative_domains = {
            'bis.doc.gov': {'weight': 10, 'type': 'government'},
            'export.gov': {'weight': 10, 'type': 'government'},
            'trade.gov': {'weight': 9, 'type': 'government'},
            'census.gov': {'weight': 8, 'type': 'government'},
            'cbp.gov': {'weight': 8, 'type': 'government'},
            'mouser.com': {'weight': 7, 'type': 'distributor'},
            'digikey.com': {'weight': 7, 'type': 'distributor'},
            'advantech.com': {'weight': 6, 'type': 'manufacturer'},
            'cisco.com': {'weight': 6, 'type': 'manufacturer'},
            'dell.com': {'weight': 6, 'type': 'manufacturer'},
            'hp.com': {'weight': 6, 'type': 'manufacturer'},
            'intel.com': {'weight': 6, 'type': 'manufacturer'}
        }
        
        # æœç´¢æŸ¥è©¢æ¨¡æ¿
        self.query_templates = {
            'official_eccn': '"{product_model}" ECCN site:bis.doc.gov OR site:export.gov',
            'distributor_eccn': '"{product_model}" ECCN site:mouser.com OR site:digikey.com',
            'manufacturer_eccn': '"{product_model}" "export control" OR "ECCN" site:{manufacturer_domain}',
            'general_eccn': '"{product_model}" ECCN "export control classification"',
            'ccl_search': '"{product_model}" "commerce control list" CCL',
            'regulatory_search': '"{product_model}" "export administration regulations" EAR',
            'specification_search': '"{product_model}" specifications datasheet ECCN'
        }

    def search_eccn_information(self, product_model: str, manufacturer: str = None) -> List[Dict]:
        """
        æœç´¢ç”¢å“çš„ECCNç›¸é—œè³‡è¨Š
        
        Args:
            product_model: ç”¢å“å‹è™Ÿ
            manufacturer: è£½é€ å•†åç¨± (å¯é¸)
            
        Returns:
            æœç´¢çµæœæ¸…å–®
        """
        try:
            self.logger.info(f" é–‹å§‹WebSearch ECCNæŸ¥è©¢: {product_model}")
            
            all_results = []
            
            # 1. å®˜æ–¹æ”¿åºœä¾†æºæœç´¢
            official_results = self._search_official_sources(product_model)
            all_results.extend(official_results)
            
            # 2. ç¶“éŠ·å•†ç¶²ç«™æœç´¢
            distributor_results = self._search_distributor_sources(product_model)
            all_results.extend(distributor_results)
            
            # 3. è£½é€ å•†ç¶²ç«™æœç´¢
            if manufacturer:
                manufacturer_results = self._search_manufacturer_sources(product_model, manufacturer)
                all_results.extend(manufacturer_results)
            
            # 4. ä¸€èˆ¬ECCNè³‡æ–™åº«æœç´¢
            general_results = self._search_general_sources(product_model)
            all_results.extend(general_results)
            
            # 5. åˆ†æå’Œæ’åºçµæœ
            processed_results = self._process_search_results(all_results, product_model)
            
            self.logger.info(f" WebSearchå®Œæˆï¼Œæ‰¾åˆ° {len(processed_results)} å€‹ç›¸é—œçµæœ")
            return processed_results
            
        except Exception as e:
            self.logger.error(f" WebSearchå¤±æ•—: {str(e)}")
            return []

    def _search_official_sources(self, product_model: str) -> List[Dict]:
        """æœç´¢å®˜æ–¹æ”¿åºœä¾†æº"""
        
        self.logger.info("ï¸ æœç´¢å®˜æ–¹æ”¿åºœä¾†æº")
        results = []
        
        queries = [
            self.query_templates['official_eccn'].format(product_model=product_model),
            f'"{product_model}" "commerce control list"',
            f'"{product_model}" "export administration regulations"'
        ]
        
        for query in queries:
            try:
                search_results = self._perform_web_search(query, source_type='official')
                results.extend(search_results)
                time.sleep(self.rate_limit_delay)
            except Exception as e:
                self.logger.warning(f"å®˜æ–¹ä¾†æºæœç´¢å¤±æ•—: {query} - {str(e)}")
        
        return results

    def _search_distributor_sources(self, product_model: str) -> List[Dict]:
        """æœç´¢ç¶“éŠ·å•†ä¾†æº"""
        
        self.logger.info(" æœç´¢ç¶“éŠ·å•†ä¾†æº")
        results = []
        
        queries = [
            self.query_templates['distributor_eccn'].format(product_model=product_model),
            f'"{product_model}" ECCN site:arrow.com',
            f'"{product_model}" "export control" site:farnell.com'
        ]
        
        for query in queries:
            try:
                search_results = self._perform_web_search(query, source_type='distributor')
                results.extend(search_results)
                time.sleep(self.rate_limit_delay)
            except Exception as e:
                self.logger.warning(f"ç¶“éŠ·å•†ä¾†æºæœç´¢å¤±æ•—: {query} - {str(e)}")
        
        return results

    def _search_manufacturer_sources(self, product_model: str, manufacturer: str) -> List[Dict]:
        """æœç´¢è£½é€ å•†ä¾†æº"""
        
        self.logger.info(f" æœç´¢è£½é€ å•†ä¾†æº: {manufacturer}")
        results = []
        
        # æ¨æ–·è£½é€ å•†ç¶²åŸŸ
        manufacturer_domain = self._infer_manufacturer_domain(manufacturer)
        
        if manufacturer_domain:
            query = self.query_templates['manufacturer_eccn'].format(
                product_model=product_model,
                manufacturer_domain=manufacturer_domain
            )
            
            try:
                search_results = self._perform_web_search(query, source_type='manufacturer')
                results.extend(search_results)
            except Exception as e:
                self.logger.warning(f"è£½é€ å•†ä¾†æºæœç´¢å¤±æ•—: {manufacturer} - {str(e)}")
        
        return results

    def _search_general_sources(self, product_model: str) -> List[Dict]:
        """æœç´¢ä¸€èˆ¬ä¾†æº"""
        
        self.logger.info(" æœç´¢ä¸€èˆ¬ä¾†æº")
        results = []
        
        queries = [
            self.query_templates['general_eccn'].format(product_model=product_model),
            self.query_templates['ccl_search'].format(product_model=product_model),
            self.query_templates['specification_search'].format(product_model=product_model)
        ]
        
        for query in queries:
            try:
                search_results = self._perform_web_search(query, source_type='general')
                results.extend(search_results)
                time.sleep(self.rate_limit_delay)
            except Exception as e:
                self.logger.warning(f"ä¸€èˆ¬ä¾†æºæœç´¢å¤±æ•—: {query} - {str(e)}")
        
        return results

    def _perform_web_search(self, query: str, source_type: str = 'general') -> List[Dict]:
        """
        åŸ·è¡Œå¯¦éš›çš„ç¶²è·¯æœç´¢
        
        æ³¨æ„: é€™è£¡ä½¿ç”¨æ¨¡æ“¬å¯¦ç¾ï¼Œå¯¦éš›éƒ¨ç½²æ™‚éœ€è¦æ•´åˆçœŸå¯¦çš„æœç´¢API
        å¦‚ Google Custom Search API, Bing Search API æˆ– DuckDuckGo API
        """
        
        # æ¨¡æ“¬æœç´¢çµæœ - å¯¦éš›å¯¦ç¾æ™‚éœ€è¦æ›¿æ›ç‚ºçœŸå¯¦çš„æœç´¢API
        mock_results = self._generate_mock_search_results(query, source_type)
        
        # çœŸå¯¦å¯¦ç¾ç¯„ä¾‹ (éœ€è¦APIé‡‘é‘°):
        # return self._google_custom_search(query)
        # return self._bing_search(query)
        # return self._duckduckgo_search(query)
        
        return mock_results

    def _generate_mock_search_results(self, query: str, source_type: str) -> List[Dict]:
        """ç”Ÿæˆæ¨¡æ“¬æœç´¢çµæœ (é–‹ç™¼å’Œæ¸¬è©¦ç”¨)"""
        
        mock_data = {
            'official': [
                {
                    'title': 'Commerce Control List - Category 5 Telecommunications',
                    'url': 'https://www.bis.doc.gov/index.php/policy-guidance/control-list-classification/commerce-control-list-classification',
                    'snippet': 'Industrial networking equipment classified under 5A991. Products with enhanced security features may require 5A991.b classification.',
                    'domain': 'bis.doc.gov'
                }
            ],
            'distributor': [
                {
                    'title': f'Search results for {query.split()[0]} - ECCN Information',
                    'url': 'https://www.mouser.com/ProductDetail/Advantech/EKI-2428G-4CA-AE',
                    'snippet': 'ECCN: 5A991 - Industrial Ethernet networking equipment. Export restrictions may apply.',
                    'domain': 'mouser.com'
                }
            ],
            'manufacturer': [
                {
                    'title': 'Product Specifications and Export Classification',
                    'url': 'https://www.advantech.com/products/eccn-classification',
                    'snippet': 'Our industrial networking products are classified according to US export control regulations. Most industrial switches fall under 5A991.',
                    'domain': 'advantech.com'
                }
            ],
            'general': [
                {
                    'title': 'Understanding ECCN Classifications for Network Equipment',
                    'url': 'https://www.exportcompliance.com/eccn-guide',
                    'snippet': 'Network switches and industrial communication equipment typically classified as 5A991 or EAR99 depending on capabilities.',
                    'domain': 'exportcompliance.com'
                }
            ]
        }
        
        return mock_data.get(source_type, [])

    def _google_custom_search(self, query: str) -> List[Dict]:
        """Google Custom Search API æ•´åˆ (éœ€è¦APIé‡‘é‘°)"""
        
        # Google Custom Search API å¯¦ç¾
        api_key = ""  # éœ€è¦è¨­å®š
        cx = ""  # Custom Search Engine ID
        
        if not api_key or not cx:
            return []
        
        url = "https://www.googleapis.com/customsearch/v1"
        params = {
            'key': api_key,
            'cx': cx,
            'q': query,
            'num': self.max_results_per_query
        }
        
        try:
            response = requests.get(url, params=params, timeout=self.timeout)
            if response.status_code == 200:
                data = response.json()
                items = data.get('items', [])
                
                return [
                    {
                        'title': item.get('title', ''),
                        'url': item.get('link', ''),
                        'snippet': item.get('snippet', ''),
                        'domain': self._extract_domain(item.get('link', ''))
                    }
                    for item in items
                ]
        except Exception as e:
            self.logger.error(f"Googleæœç´¢å¤±æ•—: {str(e)}")
        
        return []

    def _bing_search(self, query: str) -> List[Dict]:
        """Bing Search API æ•´åˆ (éœ€è¦APIé‡‘é‘°)"""
        
        api_key = ""  # éœ€è¦è¨­å®š
        
        if not api_key:
            return []
        
        url = "https://api.bing.microsoft.com/v7.0/search"
        headers = {'Ocp-Apim-Subscription-Key': api_key}
        params = {
            'q': query,
            'count': self.max_results_per_query,
            'mkt': 'en-US'
        }
        
        try:
            response = requests.get(url, headers=headers, params=params, timeout=self.timeout)
            if response.status_code == 200:
                data = response.json()
                web_pages = data.get('webPages', {}).get('value', [])
                
                return [
                    {
                        'title': page.get('name', ''),
                        'url': page.get('url', ''),
                        'snippet': page.get('snippet', ''),
                        'domain': self._extract_domain(page.get('url', ''))
                    }
                    for page in web_pages
                ]
        except Exception as e:
            self.logger.error(f"Bingæœç´¢å¤±æ•—: {str(e)}")
        
        return []

    def _process_search_results(self, raw_results: List[Dict], product_model: str) -> List[Dict]:
        """è™•ç†å’Œåˆ†ææœç´¢çµæœ"""
        
        processed_results = []
        
        for result in raw_results:
            try:
                # æå–ECCNè³‡è¨Š
                eccn_info = self._extract_eccn_from_result(result, product_model)
                
                if eccn_info:
                    # è¨ˆç®—ç›¸é—œæ€§å’Œå¯ä¿¡åº¦
                    relevance_score = self._calculate_relevance(result, product_model)
                    credibility_score = self._calculate_credibility(result)
                    
                    processed_result = {
                        **eccn_info,
                        'relevance_score': relevance_score,
                        'credibility_score': credibility_score,
                        'combined_score': (relevance_score + credibility_score) / 2,
                        'source_type': self._classify_source_type(result),
                        'timestamp': datetime.now().isoformat()
                    }
                    
                    processed_results.append(processed_result)
                    
            except Exception as e:
                self.logger.warning(f"çµæœè™•ç†å¤±æ•—: {str(e)}")
                continue
        
        # æŒ‰åˆ†æ•¸æ’åº
        processed_results.sort(key=lambda x: x['combined_score'], reverse=True)
        
        # å»é‡å’Œåˆä½µç›¸ä¼¼çµæœ
        deduplicated_results = self._deduplicate_results(processed_results)
        
        return deduplicated_results

    def _extract_eccn_from_result(self, result: Dict, product_model: str) -> Optional[Dict]:
        """å¾æœç´¢çµæœä¸­æå–ECCNè³‡è¨Š"""
        
        title = result.get('title', '')
        snippet = result.get('snippet', '')
        url = result.get('url', '')
        domain = result.get('domain', '')
        
        combined_text = f"{title} {snippet}".upper()
        
        # å°‹æ‰¾ECCNæ¨¡å¼
        eccn_matches = self.eccn_pattern.findall(combined_text)
        
        if eccn_matches:
            # é¸æ“‡æœ€å¯èƒ½çš„ECCN (æ’é™¤æ˜é¡¯ä¸ç›¸é—œçš„)
            eccn_code = self._select_best_eccn_match(eccn_matches, combined_text)
            
            return {
                'source': 'websearch',
                'eccn_code': eccn_code,
                'url': url,
                'domain': domain,
                'title': title,
                'snippet': snippet,
                'context': self._extract_context(combined_text, eccn_code),
                'confidence': self._assess_eccn_confidence(result, eccn_code, product_model)
            }
        
        return None

    def _select_best_eccn_match(self, eccn_matches: List[str], text: str) -> str:
        """å¾å¤šå€‹ECCNåŒ¹é…ä¸­é¸æ“‡æœ€ä½³çš„"""
        
        if len(eccn_matches) == 1:
            return eccn_matches[0].upper()
        
        # å„ªå…ˆç´šæ’åº
        eccn_priorities = {
            'EAR99': 1,
            '5A991': 2,
            '5A991.b': 3,
            '5A991.b.1': 4,
            '4A994': 2
        }
        
        # æŒ‰å„ªå…ˆç´šå’Œä¸Šä¸‹æ–‡ç›¸é—œæ€§æ’åº
        scored_matches = []
        for eccn in eccn_matches:
            eccn_upper = eccn.upper()
            priority = eccn_priorities.get(eccn_upper, 0)
            context_score = self._calculate_context_relevance(text, eccn_upper)
            
            scored_matches.append((eccn_upper, priority + context_score))
        
        # è¿”å›æœ€é«˜åˆ†çš„ECCN
        scored_matches.sort(key=lambda x: x[1], reverse=True)
        return scored_matches[0][0]

    def _calculate_context_relevance(self, text: str, eccn: str) -> float:
        """è¨ˆç®—ECCNåœ¨æ–‡æœ¬ä¸­çš„ä¸Šä¸‹æ–‡ç›¸é—œæ€§"""
        
        # ç›¸é—œé—œéµå­—
        relevance_keywords = {
            'EAR99': ['commercial', 'consumer', 'office', 'standard'],
            '5A991': ['industrial', 'managed', 'ethernet', 'network'],
            '5A991.b': ['security', 'encryption', 'advanced', 'enhanced'],
            '5A991.b.1': ['high-speed', 'gigabit', 'performance', 'fiber'],
            '4A994': ['management', 'monitoring', 'control', 'power']
        }
        
        keywords = relevance_keywords.get(eccn, [])
        found_keywords = sum(1 for keyword in keywords if keyword in text.lower())
        
        return found_keywords / len(keywords) if keywords else 0

    def _calculate_relevance(self, result: Dict, product_model: str) -> float:
        """è¨ˆç®—æœç´¢çµæœèˆ‡ç”¢å“çš„ç›¸é—œæ€§"""
        
        title = result.get('title', '').lower()
        snippet = result.get('snippet', '').lower()
        url = result.get('url', '').lower()
        
        model_clean = product_model.lower().replace('-', '').replace('_', '')
        
        relevance_score = 0.0
        
        # ç”¢å“å‹è™ŸåŒ¹é…
        if model_clean in title.replace('-', '').replace('_', ''):
            relevance_score += 0.4
        elif model_clean in snippet.replace('-', '').replace('_', ''):
            relevance_score += 0.3
        elif model_clean in url.replace('-', '').replace('_', ''):
            relevance_score += 0.2
        
        # ECCNç›¸é—œé—œéµå­—
        eccn_keywords = ['eccn', 'export control', 'classification', 'commerce control list']
        for keyword in eccn_keywords:
            if keyword in title or keyword in snippet:
                relevance_score += 0.1
        
        return min(relevance_score, 1.0)

    def _calculate_credibility(self, result: Dict) -> float:
        """è¨ˆç®—æœç´¢çµæœçš„å¯ä¿¡åº¦"""
        
        domain = result.get('domain', '').lower()
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºæ¬Šå¨ä¾†æº
        for auth_domain, info in self.authoritative_domains.items():
            if auth_domain in domain:
                return info['weight'] / 10.0  # æ¨™æº–åŒ–ç‚º0-1
        
        # å…¶ä»–å¯ä¿¡åº¦æŒ‡æ¨™
        credibility_score = 0.5  # åŸºç¤åˆ†æ•¸
        
        title = result.get('title', '').lower()
        snippet = result.get('snippet', '').lower()
        
        # æ­£é¢æŒ‡æ¨™
        positive_indicators = ['official', 'specification', 'datasheet', 'technical', 'manufacturer']
        negative_indicators = ['forum', 'discussion', 'blog', 'opinion', 'estimate']
        
        for indicator in positive_indicators:
            if indicator in title or indicator in snippet:
                credibility_score += 0.1
        
        for indicator in negative_indicators:
            if indicator in title or indicator in snippet:
                credibility_score -= 0.1
        
        return max(0.0, min(credibility_score, 1.0))

    def _classify_source_type(self, result: Dict) -> str:
        """åˆ†é¡ä¾†æºé¡å‹"""
        
        domain = result.get('domain', '').lower()
        
        for auth_domain, info in self.authoritative_domains.items():
            if auth_domain in domain:
                return info['type']
        
        # æ ¹æ“šåŸŸåç‰¹å¾µåˆ†é¡
        if any(gov_tld in domain for gov_tld in ['.gov', '.mil']):
            return 'government'
        elif any(edu_tld in domain for edu_tld in ['.edu', '.ac.']):
            return 'academic'
        elif 'export' in domain or 'compliance' in domain:
            return 'compliance'
        else:
            return 'general'

    def _deduplicate_results(self, results: List[Dict]) -> List[Dict]:
        """å»é‡ç›¸ä¼¼çš„æœç´¢çµæœ"""
        
        unique_results = []
        seen_eccns = set()
        
        for result in results:
            eccn = result.get('eccn_code', '')
            url = result.get('url', '')
            
            # çµ„åˆå”¯ä¸€éµ
            unique_key = f"{eccn}_{self._extract_domain(url)}"
            
            if unique_key not in seen_eccns:
                seen_eccns.add(unique_key)
                unique_results.append(result)
        
        return unique_results

    def _extract_domain(self, url: str) -> str:
        """å¾URLæå–åŸŸå"""
        
        import urllib.parse
        try:
            parsed = urllib.parse.urlparse(url)
            return parsed.netloc.lower()
        except:
            return ''

    def _extract_context(self, text: str, eccn: str) -> str:
        """æå–ECCNå‘¨åœçš„ä¸Šä¸‹æ–‡"""
        
        eccn_pos = text.upper().find(eccn.upper())
        if eccn_pos == -1:
            return ''
        
        # æå–å‰å¾Œ50å€‹å­—ç¬¦
        start = max(0, eccn_pos - 50)
        end = min(len(text), eccn_pos + len(eccn) + 50)
        
        return text[start:end].strip()

    def _assess_eccn_confidence(self, result: Dict, eccn: str, product_model: str) -> str:
        """è©•ä¼°ECCNè³‡è¨Šçš„ä¿¡å¿ƒåº¦"""
        
        relevance = self._calculate_relevance(result, product_model)
        credibility = self._calculate_credibility(result)
        
        combined_score = (relevance + credibility) / 2
        
        if combined_score >= 0.8:
            return 'high'
        elif combined_score >= 0.6:
            return 'medium'
        else:
            return 'low'

    def _infer_manufacturer_domain(self, manufacturer: str) -> Optional[str]:
        """æ¨æ–·è£½é€ å•†çš„ç¶²åŸŸåç¨±"""
        
        manufacturer_mapping = {
            'advantech': 'advantech.com',
            'cisco': 'cisco.com',
            'dell': 'dell.com',
            'hp': 'hp.com',
            'intel': 'intel.com',
            'siemens': 'siemens.com',
            'schneider': 'schneider-electric.com',
            'moxa': 'moxa.com',
            'phoenix': 'phoenixcontact.com'
        }
        
        manufacturer_lower = manufacturer.lower()
        
        for key, domain in manufacturer_mapping.items():
            if key in manufacturer_lower:
                return domain
        
        # å˜—è©¦æ§‹å»ºåŸŸå
        clean_name = re.sub(r'[^a-zA-Z]', '', manufacturer_lower)
        if len(clean_name) > 2:
            return f"{clean_name}.com"
        
        return None

# ä½¿ç”¨ç¤ºä¾‹
def test_websearch():
    """æ¸¬è©¦WebSearchåŠŸèƒ½"""
    
    import logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    
    searcher = ECCNWebSearcher(logger)
    
    test_products = [
        ("EKI-2428G-4CA-AE", "Advantech"),
        ("EKI-5525I-AE", "Advantech"),
        ("TN-5510A-2L", "Moxa")
    ]
    
    print(" WebSearch æ¸¬è©¦")
    print("=" * 50)
    
    for model, manufacturer in test_products:
        print(f"\n æœç´¢: {model} ({manufacturer})")
        
        results = searcher.search_eccn_information(model, manufacturer)
        
        print(f"æ‰¾åˆ° {len(results)} å€‹çµæœ:")
        for i, result in enumerate(results[:3], 1):  # é¡¯ç¤ºå‰3å€‹çµæœ
            print(f"  {i}. ECCN: {result.get('eccn_code', 'N/A')}")
            print(f"     ä¿¡å¿ƒåº¦: {result.get('confidence', 'unknown')}")
            print(f"     ä¾†æº: {result.get('domain', 'unknown')}")
            print(f"     åˆ†æ•¸: {result.get('combined_score', 0):.2f}")

if __name__ == "__main__":
    test_websearch()