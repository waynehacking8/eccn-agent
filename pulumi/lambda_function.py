#!/usr/bin/env python3
"""
å®Œæ•´ECCNåˆ†é¡Pipeline - å–®curlå®Œæˆæ‰€æœ‰æµç¨‹
è¨­è¨ˆæµç¨‹ï¼š
1. å„ªå…ˆMouser APIç›´æ¥æŸ¥è©¢ â†’ æ‰¾åˆ°å‰‡ç›´æ¥è¿”å›
2. æŸ¥è©¢ä¸åˆ° â†’ åŒæ™‚åŸ·è¡Œï¼šPDFç‰¹å¾µâ†’Mouserç›¸ä¼¼ç”¢å“æŸ¥è©¢ + WebSearchäº¤å‰é©—è­‰
3. å°‡æ‰€æœ‰çµæœçµ¦LLMç¶œåˆæ±ºç­–
4. é¡¯ç¤ºå®Œæ•´è³‡æ–™ä¾†æº
"""

import json
import logging
import boto3
import time
import os
from typing import Dict, List, Optional, Any
from datetime import datetime

# AWSæœå‹™è¨­å®š - å¾ç’°å¢ƒè®Šæ•¸è®€å–
AWS_ACCESS_KEY_ID = os.environ.get('AWS_ACCESS_KEY_ID')
AWS_SECRET_ACCESS_KEY = os.environ.get('AWS_SECRET_ACCESS_KEY')
AWS_REGION = os.environ.get('CUSTOM_AWS_REGION', 'us-east-1')

# S3å’ŒBedrocké…ç½®
S3_BUCKET_NAME = os.environ.get('S3_BUCKET_NAME', 'eccn-two-lambda-pipeline-data-us-east-1')
BEDROCK_MODEL_ID = os.environ.get('DEFAULT_BEDROCK_MODEL_ID', "us.anthropic.claude-3-7-sonnet-20250219-v1:0")

class CompletePipelineECCNClassifier:
    """å®Œæ•´Pipeline ECCNåˆ†é¡å™¨"""
    
    def __init__(self):
        self.logger = self._setup_logging()
        
        # AWSæœå‹™åˆå§‹åŒ–
        self.s3_client = boto3.client(
            's3',
            aws_access_key_id=AWS_ACCESS_KEY_ID,
            aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
            region_name=AWS_REGION
        )
        
        self.bedrock_client = boto3.client(
            'bedrock-runtime',
            aws_access_key_id=AWS_ACCESS_KEY_ID,
            aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
            region_name=AWS_REGION
        )
    
    def _normalize_eccn_format(self, eccn_code: str) -> str:
        """çµ±ä¸€ECCNä»£ç¢¼æ ¼å¼ - æœ€å¾Œä¸€æ®µå­—æ¯å¾Œç¶´è½‰å°å¯«"""
        if not eccn_code or not isinstance(eccn_code, str):
            return "EAR99"
        
        eccn_code = eccn_code.strip()
        
        # EAR99 ä¿æŒå¤§å¯«
        if eccn_code.upper() == 'EAR99':
            return 'EAR99'
        
        # è™•ç†å…¶ä»–ECCNä»£ç¢¼ï¼Œåªå°‡æœ€å¾Œçš„å­—æ¯å¾Œç¶´è½‰å°å¯«
        import re
        # åŒ¹é…æ ¼å¼å¦‚ï¼š5A992.C â†’ 5A992.c, 5A991.B.1 â†’ 5A991.b.1
        eccn_code = re.sub(r'\.([A-Z])(\.[0-9]+)?$', lambda m: f'.{m.group(1).lower()}{m.group(2) or ""}', eccn_code)
        
        return eccn_code
    
    def _setup_logging(self):
        """è¨­å®šæ—¥èªŒè¨˜éŒ„"""
        logger = logging.getLogger()
        logger.setLevel(logging.INFO)
        
        # æ¸…é™¤ç¾æœ‰handlers
        for handler in logger.handlers[:]:
            logger.removeHandler(handler)
        
        # è¨­å®šæ–°handler
        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        return logger
    
    def classify_eccn(self, s3_key: str, product_model: str, debug: bool = False) -> Dict[str, Any]:
        """åŸ·è¡Œå®Œæ•´Pipeline ECCNåˆ†é¡"""
        start_time = time.time()
        
        self.logger.info(f"ğŸš€ é–‹å§‹å®Œæ•´Pipeline ECCNåˆ†é¡: {product_model}")
        
        try:
            # æ­¥é©Ÿ1: å„ªå…ˆMouser APIç›´æ¥æŸ¥è©¢
            self.logger.info("ğŸ” æ­¥é©Ÿ1: Mouser APIç›´æ¥æŸ¥è©¢...")
            mouser_direct_result = self._mouser_direct_search(product_model)
            
            if mouser_direct_result and mouser_direct_result.get('eccn_code'):
                # æ‰¾åˆ°ç›´æ¥åŒ¹é…ï¼Œç«‹å³è¿”å›
                self.logger.info(f"âœ… Mouser APIç›´æ¥æ‰¾åˆ°: {mouser_direct_result.get('eccn_code')}")
                return self._create_success_response({
                    'eccn_code': mouser_direct_result.get('eccn_code'),
                    'confidence': mouser_direct_result.get('confidence', 'high'),
                    'method': 'mouser_api_direct',
                    'reasoning': f'Mouser APIç›´æ¥æŸ¥è©¢çµæœ: {mouser_direct_result.get("reasoning", "")}',
                    'data_sources': {
                        'primary_source': 'mouser_api_direct',
                        'mouser_direct': 'âœ… æˆåŠŸ',
                        'pdf_feature_analysis': 'âŒ æœªåŸ·è¡Œï¼ˆå·²æ‰¾åˆ°ç›´æ¥åŒ¹é…ï¼‰',
                        'mouser_similar_search': 'âŒ æœªåŸ·è¡Œï¼ˆå·²æ‰¾åˆ°ç›´æ¥åŒ¹é…ï¼‰',
                        'websearch_validation': 'âŒ æœªåŸ·è¡Œï¼ˆå·²æ‰¾åˆ°ç›´æ¥åŒ¹é…ï¼‰',
                        'llm_decision': 'âŒ æœªåŸ·è¡Œï¼ˆå·²æ‰¾åˆ°ç›´æ¥åŒ¹é…ï¼‰'
                    },
                    'processing_time': f"{time.time() - start_time:.2f}s"
                })
            
            # æ­¥é©Ÿ2: Mouser APIæœªæ‰¾åˆ°ï¼Œç›´æ¥é€²å…¥æŠ€è¡“è¦æ ¼åˆ†æ
            self.logger.info("âŒ Mouser APIç›´æ¥æŸ¥è©¢æœªæ‰¾åˆ°ï¼Œé–‹å§‹PDFæŠ€è¡“è¦æ ¼åˆ†æ...")
            
            # 2.1 ç²å–PDFæŠ€è¡“å…§å®¹
            pdf_content = self._get_pdf_content(s3_key)
            if not pdf_content:
                return self._create_error_response("ç„¡æ³•ç²å–PDFå…§å®¹", s3_key)
            
            # 2.2 æå–PDFæŠ€è¡“è¦æ ¼
            self.logger.info("ğŸ“‹ æå–PDFæŠ€è¡“è¦æ ¼...")
            technical_specs = self._extract_technical_specifications(pdf_content)
            
            # 2.3 åŸºæ–¼æŠ€è¡“è¦æ ¼åŸ·è¡ŒMouserç›¸ä¼¼ç”¢å“æŸ¥è©¢
            self.logger.info("ğŸ” åŸºæ–¼æŠ€è¡“è¦æ ¼åŸ·è¡ŒMouserç›¸ä¼¼ç”¢å“æŸ¥è©¢...")
            mouser_similar_result = self._mouser_similar_search(pdf_content, product_model)
            websearch_result = self._websearch_validation(product_model)
            
            # æ­¥é©Ÿ3: åŸºæ–¼æŠ€è¡“è¦æ ¼çš„LLMåˆ†é¡æ±ºç­– 
            self.logger.info("ğŸ¤– åŸºæ–¼æŠ€è¡“è¦æ ¼é€²è¡ŒLLMåˆ†é¡æ±ºç­–...")
            final_classification = self._specification_based_classification(
                pdf_content, 
                product_model,
                technical_specs,
                mouser_similar_result,
                websearch_result
            )
            
            # æ ¼å¼åŒ–æœ€çµ‚çµæœ
            final_result = self._format_comprehensive_response(
                final_classification,
                mouser_similar_result,
                websearch_result,
                start_time,
                debug
            )
            
            self.logger.info(f"âœ… Pipelineå®Œæˆ: {final_result.get('eccn_code')} ({time.time() - start_time:.2f}s)")
            return self._create_success_response(final_result)
            
        except Exception as e:
            self.logger.error(f"âŒ Pipelineå¤±æ•—: {str(e)}")
            # æœ€çµ‚å¤±æ•—ä¿è­· - æ°¸é ä¸è¿”å›null
            failsafe_result = self._get_failsafe_classification(product_model)
            return self._create_success_response(failsafe_result)
    
    def _extract_technical_specifications(self, pdf_content: str) -> Dict:
        """å¾PDFå…§å®¹æå–æŠ€è¡“è¦æ ¼"""
        try:
            # æå–é—œéµæŠ€è¡“è¦æ ¼
            specs = {
                'temperature_range': self._extract_temperature_range(pdf_content),
                'power_specifications': self._extract_power_specs(pdf_content),
                'management_features': self._extract_management_features(pdf_content),
                'port_information': self._extract_port_info(pdf_content),
                'performance_specs': self._extract_performance_specs(pdf_content),
                'security_features': self._extract_security_features(pdf_content),
                'environmental_ratings': self._extract_environmental_ratings(pdf_content)
            }
            return specs
        except Exception as e:
            self.logger.warning(f"âš ï¸ æŠ€è¡“è¦æ ¼æå–å¤±æ•—: {str(e)}")
            return {}
    
    def _extract_temperature_range(self, pdf_content: str) -> str:
        """æå–å·¥ä½œæº«åº¦ç¯„åœ"""
        import re
        # æŸ¥æ‰¾æº«åº¦ç¯„åœæ¨¡å¼
        temp_patterns = [
            r'(-?\d+)Â°C\s*(?:to|~|-)\s*\+?(\d+)Â°C',
            r'Operating Temperature[:\s]+(-?\d+)Â°C\s*(?:to|~|-)\s*\+?(\d+)Â°C',
            r'Temperature[:\s]+(-?\d+)Â°C\s*(?:to|~|-)\s*\+?(\d+)Â°C'
        ]
        
        for pattern in temp_patterns:
            match = re.search(pattern, pdf_content, re.IGNORECASE)
            if match:
                return f"{match.group(1)}Â°C to +{match.group(2)}Â°C"
        return "Not specified"
    
    def _extract_power_specs(self, pdf_content: str) -> str:
        """æå–é›»æºè¦æ ¼"""
        import re
        # æŸ¥æ‰¾é›»æºè¦æ ¼
        if re.search(r'12V|24V|48V.*DC', pdf_content, re.IGNORECASE):
            return "DC Power"
        elif re.search(r'100-240V.*AC', pdf_content, re.IGNORECASE):
            return "AC Power"
        elif re.search(r'AC/DC|DC/AC', pdf_content, re.IGNORECASE):
            return "AC/DC Hybrid"
        return "Not specified"
    
    def _extract_management_features(self, pdf_content: str) -> str:
        """æå–ç®¡ç†åŠŸèƒ½"""
        import re
        features = []
        if re.search(r'SNMP|Simple Network Management', pdf_content, re.IGNORECASE):
            features.append("SNMP")
        if re.search(r'Web.*GUI|Web.*Interface|HTTP', pdf_content, re.IGNORECASE):
            features.append("Web GUI")
        if re.search(r'CLI|Command.*Line|Telnet|SSH', pdf_content, re.IGNORECASE):
            features.append("CLI")
        if re.search(r'Unmanaged|No.*Management', pdf_content, re.IGNORECASE):
            return "Unmanaged"
        return ", ".join(features) if features else "Basic/Unmanaged"
    
    def _extract_security_features(self, pdf_content: str) -> str:
        """æå–å®‰å…¨åŠŸèƒ½"""
        import re
        features = []
        if re.search(r'VPN|Virtual Private Network', pdf_content, re.IGNORECASE):
            features.append("VPN")
        if re.search(r'Encryption|Encrypt', pdf_content, re.IGNORECASE):
            features.append("Encryption")
        if re.search(r'Firewall|Access Control List|ACL', pdf_content, re.IGNORECASE):
            features.append("Firewall/ACL")
        if re.search(r'802\.1X|Authentication|AAA', pdf_content, re.IGNORECASE):
            features.append("Authentication")
        return ", ".join(features) if features else "None specified"
    
    def _extract_performance_specs(self, pdf_content: str) -> str:
        """æå–æ€§èƒ½è¦æ ¼"""
        import re
        # æŸ¥æ‰¾äº¤æ›å®¹é‡
        capacity_match = re.search(r'(\d+)\s*Gbps|(\d+)\s*Mbps', pdf_content, re.IGNORECASE)
        if capacity_match:
            if capacity_match.group(1):
                return f"{capacity_match.group(1)} Gbps"
            else:
                return f"{capacity_match.group(2)} Mbps" 
        return "Not specified"
    
    def _extract_environmental_ratings(self, pdf_content: str) -> str:
        """æå–ç’°å¢ƒä¿è­·ç­‰ç´š"""
        import re
        if re.search(r'IP\d+|IP\s*\d+', pdf_content, re.IGNORECASE):
            ip_match = re.search(r'IP\s*(\d+)', pdf_content, re.IGNORECASE)
            if ip_match:
                return f"IP{ip_match.group(1)}"
        if re.search(r'DIN.*rail|DIN-rail', pdf_content, re.IGNORECASE):
            return "DIN-rail mounting"
        return "Not specified"
    
    def _get_failsafe_classification(self, product_model: str) -> Dict:
        """Final failsafe classification - ensures never returns null"""
        self.logger.info("ğŸ›¡ï¸ Activating failsafe classification...")
        
        # Conservative classification based on product type
        if not product_model:
            eccn_code = 'EAR99'  # Default to commercial grade
            reasoning = 'No product model provided - defaulting to commercial grade classification'
        else:
            model = product_model.upper()
            
            # Conservative technical assessment
            if 'EKI' in model:
                # Industrial networking equipment default
                eccn_code = '5A991'
                reasoning = f'Failsafe classification: {product_model} appears to be industrial networking equipment - conservative 5A991 classification'
            else:
                # Unknown product type - conservative commercial
                eccn_code = 'EAR99'
                reasoning = f'Failsafe classification: {product_model} - conservative commercial grade classification due to uncertainty'
        
        return {
            'eccn_code': self._normalize_eccn_format(eccn_code),
            'confidence': 'low',
            'method': 'failsafe_classification',
            'reasoning': reasoning,
            'data_sources': {
                'primary_source': 'failsafe_pattern_matching',
                'mouser_direct': 'âŒ å¤±æ•—',
                'pattern_matching': 'âŒ å¤±æ•—',
                'pdf_feature_analysis': 'âŒ å¤±æ•—',
                'mouser_similar_search': 'âŒ å¤±æ•—', 
                'websearch_validation': 'âŒ å¤±æ•—',
                'llm_decision': 'âŒ å¤±æ•—',
                'failsafe_protection': 'âœ… å·²å•Ÿå‹•'
            },
            'processing_time': '0.01s',
            'warning': 'This is a failsafe classification - manual review recommended'
        }

    def _mouser_direct_search(self, product_model: str) -> Optional[Dict]:
        """Mouser APIç›´æ¥æŸ¥è©¢"""
        try:
            from tools import ECCNToolEnhancer
            tool_enhancer = ECCNToolEnhancer(self.logger)
            
            result = tool_enhancer.search_mouser_eccn(product_model)
            
            if result and result.get('eccn_code'):
                self.logger.info(f"âœ… Mouserç›´æ¥æŸ¥è©¢æˆåŠŸ: {result.get('eccn_code')}")
                return result
            else:
                self.logger.info("âŒ Mouserç›´æ¥æŸ¥è©¢æœªæ‰¾åˆ°åŒ¹é…")
                return None
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ Mouserç›´æ¥æŸ¥è©¢å¤±æ•—: {str(e)}")
            return None
    
    def _mouser_similar_search(self, pdf_content: str, product_model: str) -> Dict:
        """PDF feature-based Mouser similarity search"""
        try:
            self.logger.info("ğŸ” Mouser similarity analysis starting...")
            
            from mouser_algorithm import MouserSimilarityAnalyzer
            
            # Initialize analyzer
            analyzer = MouserSimilarityAnalyzer(logger=self.logger)
            
            # Run similarity analysis
            result = analyzer.analyze_similar_products(pdf_content, product_model)
            
            if result.get('status') == 'success':
                self.logger.info(f"âœ… Mouser analysis successful: {result.get('eccn_code')} (confidence: {result.get('confidence')})")
                
                # Pass results to LLM for final decision
                return {
                    'status': 'success',
                    'eccn_suggestions': [result],
                    'similar_products_count': result.get('similar_products_count', 0),
                    'method': 'mouser_similarity',
                    'confidence': result.get('confidence'),
                    'reasoning': result.get('reasoning'),
                    'technical_analysis': result.get('technical_analysis'),
                    'eccn_distribution': result.get('eccn_distribution')
                }
            else:
                self.logger.info(f"âŒ Mouser analysis failed: {result.get('error', 'Unknown error')}")
                return {
                    'status': 'no_results',
                    'eccn_suggestions': [],
                    'similar_products_count': 0,
                    'method': 'mouser_similarity',
                    'error': result.get('error')
                }
                
        except Exception as e:
            self.logger.error(f"âš ï¸ Mouser similarity analysis exception: {str(e)}")
            
            # Fallback to original method if enhanced fails
            try:
                self.logger.info("ğŸ”„ Falling back to original Mouser method...")
                from tools import MouserAPIClient
                mouser_client = MouserAPIClient(logger=self.logger)
                
                result = mouser_client.search_by_features(pdf_content, product_model)
                
                if result and result.get('eccn_code'):
                    return {
                        'status': 'success',
                        'eccn_suggestions': [result],
                        'similar_products_count': result.get('similar_products_count', 0),
                        'method': 'fallback_mouser_similarity'
                    }
                    
            except Exception as fallback_error:
                self.logger.error(f"âš ï¸ Fallback Mouser method also failed: {str(fallback_error)}")
            
            return {
                'status': 'failed',
                'error': str(e),
                'eccn_suggestions': [],
                'method': 'enhanced_mouser_similarity'
            }
    
    def _websearch_validation(self, product_model: str) -> Dict:
        """WebSearchäº¤å‰é©—è­‰"""
        try:
            self.logger.info("ğŸŒ åŸ·è¡ŒWebSearchäº¤å‰é©—è­‰...")
            
            from websearch import ECCNWebSearcher
            web_searcher = ECCNWebSearcher(self.logger)
            
            results = web_searcher.search_eccn_information(product_model, "Advantech")
            
            if results:
                self.logger.info(f"âœ… WebSearchæ‰¾åˆ° {len(results)} å€‹æ¬Šå¨ä¾†æº")
                return {
                    'status': 'success',
                    'eccn_suggestions': results[:5],  # å–å‰5å€‹æœ€ç›¸é—œ
                    'sources_count': len(results),
                    'method': 'websearch_cross_validation'
                }
            else:
                self.logger.info("âŒ WebSearchæœªæ‰¾åˆ°ç›¸é—œä¾†æº")
                return {
                    'status': 'no_results',
                    'eccn_suggestions': [],
                    'sources_count': 0,
                    'method': 'websearch_cross_validation'
                }
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ WebSearchäº¤å‰é©—è­‰å¤±æ•—: {str(e)}")
            return {
                'status': 'failed',
                'error': str(e),
                'eccn_suggestions': [],
                'method': 'websearch_cross_validation'
            }
    
    def _specification_based_classification(self, pdf_content: str, product_model: str,
                                  technical_specs: Dict, mouser_similar: Dict, websearch: Dict) -> Dict:
        """LLMç¶œåˆæ±ºç­–æ‰€æœ‰ä¾†æºçµæœ"""
        try:
            self.logger.info("ğŸ¤– åŸ·è¡ŒLLMç¶œåˆæ±ºç­–...")
            
            # Gigabitæª¢æ¸¬ç¾åœ¨ç”±prompts.pyä¸­çš„æ™ºèƒ½é‚è¼¯è™•ç†ï¼Œä¸å†ä½¿ç”¨ç¡¬ç·¨ç¢¼è¦†è“‹
            
            # å®‰å…¨åŠŸèƒ½æª¢æ¸¬ç¾åœ¨ç”±prompts.pyä¸­çš„æ™ºèƒ½é‚è¼¯è™•ç†ï¼Œä¸å†ä½¿ç”¨ç¡¬ç·¨ç¢¼è¦†è“‹
            self.logger.info("ğŸ“‹ æ‰€æœ‰åˆ†é¡é‚è¼¯ç¾åœ¨çµ±ä¸€ç”±prompts.pyæ™ºèƒ½è™•ç†ï¼Œé–‹å§‹LLMç¶œåˆåˆ†æ...")
            
            # æº–å‚™ç¶œåˆä¸Šä¸‹æ–‡
            context = self._prepare_comprehensive_context(mouser_similar, websearch)
            
            # å°å…¥æŠ€è¡“è¦æ ¼æç¤ºè©
            from prompts import SYSTEM_PROMPT
            
            system_prompt = SYSTEM_PROMPT

            user_prompt = f"""
Product Model: {product_model}

Technical Specifications Analysis:
- Operating Temperature: {technical_specs.get('temperature_range', 'Not specified')}
- Power Specifications: {technical_specs.get('power_specifications', 'Not specified')}
- Management Features: {technical_specs.get('management_features', 'Not specified')}
- Security Features: {technical_specs.get('security_features', 'Not specified')}
- Performance Specifications: {technical_specs.get('performance_specs', 'Not specified')}
- Environmental Protection: {technical_specs.get('environmental_ratings', 'Not specified')}

MOUSER Similar Products Analysis:
{context['mouser_context']}

WEBSEARCH Cross-Validation:
{context['websearch_context']}

PDF Technical Content:
{pdf_content[:4000]}

Please perform ECCN classification based on technical specifications, with primary focus on temperature range and power specifications as key decision criteria.

Analysis Requirements:
1. If multiple sources consistently suggest the same ECCN, give high weight to that classification
2. Explain how each source influences your decision
3. Provide clear decision logic based on technical specifications
4. Focus on measurable technical parameters rather than product naming patterns

Please respond in JSON format."""

            # èª¿ç”¨Bedrock
            response = self.bedrock_client.invoke_model(
                modelId=BEDROCK_MODEL_ID,
                body=json.dumps({
                    "anthropic_version": "bedrock-2023-05-31",
                    "max_tokens": 4000,
                    "system": system_prompt,
                    "messages": [{"role": "user", "content": user_prompt}]
                })
            )
            
            response_body = json.loads(response['body'].read())
            llm_text = response_body['content'][0]['text']
            
            # è§£æJSONå›æ‡‰
            try:
                result = json.loads(llm_text)
                result['method'] = 'llm_comprehensive_decision'
                result['raw_llm_response'] = llm_text
                return result
            except json.JSONDecodeError:
                # è™•ç†éJSONå›æ‡‰
                self.logger.warning("âš ï¸ LLMå›æ‡‰éJSONæ ¼å¼ï¼Œå˜—è©¦è§£æ")
                return self._parse_non_json_llm_response(llm_text, product_model)
                
        except Exception as e:
            self.logger.error(f"âŒ LLMç¶œåˆæ±ºç­–å¤±æ•—: {str(e)}")
            # ä½¿ç”¨å¤±æ•—ä¿è­·åˆ†é¡
            failsafe = self._get_failsafe_classification(product_model)
            return {
                'eccn_code': failsafe['eccn_code'],
                'confidence': 'low',
                'reasoning': f'LLMç¶œåˆæ±ºç­–å¤±æ•—ï¼Œä½¿ç”¨å¤±æ•—ä¿è­·åˆ†é¡: {failsafe["reasoning"]}',
                'method': 'llm_comprehensive_decision_failed_with_failsafe'
            }
    
    def _prepare_comprehensive_context(self, mouser_similar: Dict, websearch: Dict) -> Dict:
        """æº–å‚™ç¶œåˆä¸Šä¸‹æ–‡"""
        
        # Mouserç›¸ä¼¼ç”¢å“ä¸Šä¸‹æ–‡
        mouser_context = "Mouserç›¸ä¼¼ç”¢å“åˆ†æ:\n"
        if mouser_similar.get('status') == 'success':
            suggestions = mouser_similar.get('eccn_suggestions', [])
            if suggestions:
                for i, suggestion in enumerate(suggestions, 1):
                    eccn = suggestion.get('eccn_code', 'N/A')
                    confidence = suggestion.get('confidence', 'N/A')
                    reasoning = suggestion.get('reasoning', '')[:200]
                    mouser_context += f"{i}. ECCNå»ºè­°: {eccn} (ä¿¡å¿ƒåº¦: {confidence})\n"
                    mouser_context += f"   ç†ç”±: {reasoning}...\n"
            else:
                mouser_context += "æœªæ‰¾åˆ°ç›¸ä¼¼ç”¢å“\n"
        else:
            mouser_context += f"æŸ¥è©¢å¤±æ•—: {mouser_similar.get('error', 'Unknown')}\n"
        
        # WebSearchæ¬Šå¨ä¾†æºä¸Šä¸‹æ–‡
        websearch_context = "WebSearchæ¬Šå¨ä¾†æºåˆ†æ:\n"
        if websearch.get('status') == 'success':
            suggestions = websearch.get('eccn_suggestions', [])
            if suggestions:
                for i, suggestion in enumerate(suggestions, 1):
                    eccn = suggestion.get('eccn_code', 'N/A')
                    domain = suggestion.get('domain', 'N/A')
                    confidence = suggestion.get('confidence', 'N/A')
                    snippet = suggestion.get('snippet', '')[:150]
                    websearch_context += f"{i}. ä¾†æº: {domain}\n"
                    websearch_context += f"   ECCNå»ºè­°: {eccn} (ä¿¡å¿ƒåº¦: {confidence})\n"
                    websearch_context += f"   æ‘˜è¦: {snippet}...\n"
            else:
                websearch_context += "æœªæ‰¾åˆ°æ¬Šå¨ä¾†æº\n"
        else:
            websearch_context += f"æŸ¥è©¢å¤±æ•—: {websearch.get('error', 'Unknown')}\n"
        
        return {
            'mouser_context': mouser_context,
            'websearch_context': websearch_context
        }
    
    def _parse_non_json_llm_response(self, llm_text: str, product_model: str) -> Dict:
        """è§£æéJSONæ ¼å¼çš„LLMå›æ‡‰"""
        import re
        
        # å˜—è©¦æå–ECCNä»£ç¢¼
        eccn_pattern = r'\b(EAR99|[0-9][A-Z][0-9]{3}(?:\.[a-z](?:\.[0-9]+)?)?)\b'
        eccn_matches = re.findall(eccn_pattern, llm_text, re.IGNORECASE)
        
        if eccn_matches:
            eccn_code = self._normalize_eccn_format(eccn_matches[0])
        else:
            # ä½¿ç”¨å¤±æ•—ä¿è­·åˆ†é¡ï¼Œä¸è¿”å›Unknown
            failsafe = self._get_failsafe_classification(product_model)
            eccn_code = self._normalize_eccn_format(failsafe['eccn_code'])
        
        return {
            'eccn_code': eccn_code,
            'confidence': 'medium',
            'reasoning': f'å¾LLMå›æ‡‰ä¸­è§£æ: {llm_text[:500]}...',
            'method': 'llm_comprehensive_decision_parsed',
            'raw_llm_response': llm_text
        }
    
    def _format_comprehensive_response(self, classification: Dict, mouser_similar: Dict,
                                     websearch: Dict, start_time: float, debug: bool) -> Dict:
        """æ ¼å¼åŒ–ç¶œåˆå›æ‡‰"""
        processing_time = time.time() - start_time
        
        # Determine the method based on which enhanced algorithm was used
        method = 'complete_pipeline'
        if mouser_similar.get('method') == 'enhanced_mouser_similarity':
            method = 'enhanced_mouser_similarity'
        elif mouser_similar.get('method') == 'fallback_mouser_similarity':
            method = 'fallback_mouser_similarity'
        
        result = {
            'eccn_code': classification.get('eccn_code', 'Unknown'),
            'confidence': classification.get('confidence', 'low'),
            'reasoning': classification.get('reasoning', ''),
            'method': method,
            'data_sources': {
                'primary_source': 'llm_comprehensive_decision',
                'mouser_direct': 'âŒ æœªæ‰¾åˆ°ç›´æ¥åŒ¹é…',
                'pdf_feature_analysis': 'âœ… å·²åŸ·è¡Œ',
                'mouser_similar_search': 'âœ… å·²åŸ·è¡Œ' if mouser_similar.get('status') == 'success' else 'âŒ å¤±æ•—',
                'websearch_validation': 'âœ… å·²åŸ·è¡Œ' if websearch.get('status') == 'success' else 'âŒ å¤±æ•—',
                'llm_decision': 'âœ… ç¶œåˆæ±ºç­–å®Œæˆ'
            },
            'source_details': {
                'mouser_similar_products': mouser_similar.get('similar_products_count', 0),
                'websearch_sources': websearch.get('sources_count', 0),
                'mouser_influence': classification.get('mouser_influence', ''),
                'websearch_influence': classification.get('websearch_influence', ''),
                'mouser_method': mouser_similar.get('method', 'unknown')
            },
            'processing_time': f"{processing_time:.2f}s",
            'timestamp': datetime.now().isoformat(),
            'version': 'enhanced_pipeline_v1.1'
        }
        
        # Add enhanced algorithm details if available
        if mouser_similar.get('method') == 'enhanced_mouser_similarity' and mouser_similar.get('eccn_distribution'):
            result['enhanced_details'] = {
                'eccn_distribution': mouser_similar.get('eccn_distribution'),
                'technical_analysis': mouser_similar.get('technical_analysis'),
                'enhanced_confidence': mouser_similar.get('confidence')
            }
        
        if debug:
            result['debug_info'] = {
                'mouser_similar_details': mouser_similar,
                'websearch_details': websearch,
                'llm_classification_details': classification,
                'pdf_evidence': classification.get('pdf_evidence', []),
                'decision_factors': classification.get('decision_factors', [])
            }
        
        return result
    
    def _get_pdf_content(self, s3_key: str) -> Optional[str]:
        """å¾S3ç²å–PDFå…§å®¹"""
        try:
            self.logger.info(f"ğŸ“„ å¾S3ç²å–PDFå…§å®¹: {s3_key}")
            
            response = self.s3_client.get_object(Bucket=S3_BUCKET_NAME, Key=s3_key)
            content = response['Body'].read().decode('utf-8')
            
            self.logger.info(f"âœ… æˆåŠŸç²å–PDFå…§å®¹ ({len(content)} å­—ç¬¦)")
            return content
            
        except Exception as e:
            self.logger.error(f"âŒ ç„¡æ³•ç²å–PDFå…§å®¹: {str(e)}")
            return None
    
    def _create_success_response(self, data: Dict) -> Dict:
        """å‰µå»ºæˆåŠŸå›æ‡‰"""
        return {
            'statusCode': 200,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            'body': {
                'success': True,
                'classification': data
            }
        }
    
    def _create_error_response(self, message: str, s3_key: str = None) -> Dict:
        """å‰µå»ºéŒ¯èª¤å›æ‡‰"""
        return {
            'statusCode': 500,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            'body': {
                'success': False,
                'error': message,
                's3_key': s3_key,
                'timestamp': datetime.now().isoformat()
            }
        }

def lambda_handler(event, context):
    """Lambdaè™•ç†å‡½æ•¸"""
    classifier = CompletePipelineECCNClassifier()
    
    try:
        # è§£æè«‹æ±‚
        if isinstance(event.get('body'), str):
            body = json.loads(event['body'])
        else:
            body = event.get('body', event)
        
        s3_key = body.get('s3_key')
        product_model = body.get('product_model')
        debug = body.get('debug', False)
        
        if not s3_key or not product_model:
            return classifier._create_error_response("ç¼ºå°‘å¿…è¦åƒæ•¸: s3_key å’Œ product_model")
        
        # åŸ·è¡Œå®Œæ•´Pipelineåˆ†é¡
        return classifier.classify_eccn(s3_key, product_model, debug)
        
    except Exception as e:
        return classifier._create_error_response(f"è«‹æ±‚è™•ç†å¤±æ•—: {str(e)}")

# æœ¬åœ°æ¸¬è©¦
if __name__ == "__main__":
    # æ¨¡æ“¬Lambdaäº‹ä»¶
    test_event = {
        'body': {
            's3_key': 'parsed/pdf_20250728_033546_591daade.json',
            'product_model': 'EKI-5729FI-MB',
            'debug': True
        }
    }
    
    print("ğŸ§ª æ¸¬è©¦å®Œæ•´Pipeline ECCNåˆ†é¡å™¨...")
    result = lambda_handler(test_event, None)
    print(json.dumps(result, indent=2, ensure_ascii=False))